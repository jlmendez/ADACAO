{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c85330",
   "metadata": {},
   "source": [
    "%%javascript\n",
    "IPython.notebook.kernel.execute(\"clear_output()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de módulos del sistema\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "# Importación de librerías para manipulación de datos y cálculos numéricos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importación de la librería Obspy para procesamiento de datos sísmicos\n",
    "import obspy\n",
    "from obspy import read, Trace, UTCDateTime as UTC\n",
    "from obspy.signal.util import _npts2nfft\n",
    "from obspy.signal.invsim import cosine_taper\n",
    "from obspy.signal import cross_correlation as occ\n",
    "from obspy.signal.cross_correlation import correlation_detector\n",
    "from obspy.signal.filter import bandpass, lowpass\n",
    "from obspy.signal.regression import linear_regression\n",
    "from obspy.core.util.base import _get_function_from_entry_point\n",
    "from obspy.core.inventory import Inventory, Network, Station, Channel, Site\n",
    "from obspy.signal.trigger import (classic_sta_lta, classic_sta_lta_py, \n",
    "                                  plot_trigger, z_detect, recursive_sta_lta, \n",
    "                                  carl_sta_trig)\n",
    "\n",
    "# Importación de la librería Scipy para cálculos científicos y procesamiento de señales\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import stats as st\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import (hilbert, correlate, correlation_lags, argrelextrema, \n",
    "                          savgol_filter)\n",
    "from scipy.stats import (percentileofscore, gaussian_kde, kurtosis, skew, \n",
    "                         pearsonr, norm)\n",
    "from scipy.fftpack import (fft, fftfreq, fftshift, ifft, next_fast_len)\n",
    "\n",
    "# Importación de módulos para manejo de fechas y zonas horarias\n",
    "from datetime import tzinfo, timezone\n",
    "\n",
    "# Importación de la librería Colorama para formato de texto en la terminal\n",
    "from colorama import init, Fore, Style\n",
    "\n",
    "# Importación de la librería Matplotlib para visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Importación de la librería Seaborn para visualización de datos con Matplotlib\n",
    "import seaborn as sns\n",
    "sns.set()  # Configuración del estilo por defecto de Seaborn\n",
    "\n",
    "# Importación de la librería Scikit-learn para algoritmos de Machine Learning\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Importación de herramientas de IPython para visualización en notebooks\n",
    "from IPython.display import Image\n",
    "\n",
    "# Aquí iría el resto de tu código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87073407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution(x, media, desv_est):\n",
    "    return np.exp(-1*((x-media)**2)/(2*(desv_est**2)))/(math.sqrt(2*np.pi) * desv_est)\n",
    "def contador_explosiones (signal_tr, stalta_array, trg_on, trg_off):\n",
    "    detections = []\n",
    "    tr_times = []\n",
    "    tr_time_ini = []\n",
    "    tr_time_fin = []\n",
    "    explo_count = 0\n",
    "    ybp_array = []\n",
    "    cft_sv_array =[]\n",
    "    explode = []\n",
    "    for v in signal_tr.times(\"utcdatetime\")  :\n",
    "        tr_times.append([v])\n",
    "\n",
    "        \n",
    "    for v in signal_tr.data:\n",
    "        ybp_array.append([v])\n",
    "    \n",
    "    for v in stalta_array:\n",
    "        cft_sv_array.append([v])\n",
    "        \n",
    "    evtgr = 0  \n",
    "\n",
    "    for i  in np.arange(len(ybp_array)):\n",
    "        if cft_sv_array[i] > trg_on and  evtgr ==0:\n",
    "            evtgr = 1\n",
    "            tr_time_ini.append(tr_times[i])\n",
    "        if cft_sv_array[i] < trg_off and evtgr ==1:\n",
    "            evtgr = 0\n",
    "            tr_time_fin.append(tr_times[i])\n",
    "            explo_count +=1\n",
    "            explode.append([explo_count-1])\n",
    " \n",
    "    if len(tr_time_ini) > len(tr_time_fin):   # Verifica si tr_time_ini es más grande que tr_time_fin\n",
    "        tr_time_ini = tr_time_ini[:len(tr_time_fin)]   # Reduce el tamaño de tr_time_ini al tamaño de tr_time_fin\n",
    "    else:\n",
    "        tr_time_fin = tr_time_fin[:len(tr_time_ini)]   # Reduce el tamaño de tr_time_fin al tamaño de tr_time_ini\n",
    "\n",
    "\n",
    "    the_times = np.concatenate((explode,tr_time_ini,tr_time_fin),axis=1)\n",
    "    the_times_df = pd.DataFrame(the_times, columns = ['explode','time_start','time_end'] )\n",
    "\n",
    "    return explo_count, tr_time_ini, tr_time_fin, the_times_df\n",
    "\n",
    "def contador_explosiones_simple (signal_tr, stalta_array, trg_on, trg_off):\n",
    "    detections = []\n",
    "    explo_count = 0\n",
    "    ybp_array = []\n",
    "    cft_sv_array =[]\n",
    "    explode = []\n",
    "        \n",
    "    for v in signal_tr.data:\n",
    "        ybp_array.append([v])\n",
    "    \n",
    "    for v in stalta_array:\n",
    "        cft_sv_array.append([v])\n",
    "\n",
    "    evtgr = 0  \n",
    "\n",
    "    for i  in np.arange(len(ybp_array)):\n",
    "        if (cft_sv_array[i]) > trg_on and  evtgr ==0:\n",
    "            evtgr = 1\n",
    "        if (cft_sv_array[i]) < trg_off and evtgr ==1:\n",
    "            evtgr = 0\n",
    "            explo_count +=1\n",
    "            \n",
    "\n",
    "    return explo_count\n",
    "\n",
    "def string_to_utcdatetime(string_v):\n",
    "    hay_milis = True\n",
    "    string_v = str(string_v)\n",
    "    y_ini =13\n",
    "    y_fin = (string_v.find(',',13))\n",
    "    m_fin = string_v.find(',',y_fin+1)\n",
    "    d_fin = string_v.find(',',m_fin+1)\n",
    "    h_fin = string_v.find(',',d_fin+1)\n",
    "    mi_fin = string_v.find(',',h_fin+1)\n",
    "    s_fin = string_v.find(',',mi_fin+1)\n",
    "    if s_fin == -1:\n",
    "        s_fin = tini.find(')',mi_fin+1)\n",
    "        hay_milis = False\n",
    "    else:\n",
    "        mili_fin = string_v.find(')', s_fin+1)\n",
    "    \n",
    "    y=(int(string_v[y_ini:y_fin]))\n",
    "    m=(int(string_v[y_fin+1:m_fin]))\n",
    "    d=(int(string_v[m_fin+1:d_fin]))\n",
    "    h=(int(string_v[d_fin+1:h_fin]))\n",
    "    mi=(int(string_v[h_fin+1:mi_fin]))\n",
    "    s=(int(string_v[mi_fin+1:s_fin]))\n",
    "    if hay_milis:\n",
    "        mili=(int(string_v[s_fin+1:mili_fin]))\n",
    "        return UTCDateTime(y,m,d,h,mi,s,mili)\n",
    "    else:\n",
    "        return UTCDateTime(y,m,d,h,mi,s)\n",
    "\n",
    "def similarity_component_thres(ccs, thres, num_components):\n",
    "    \"\"\"Return Trace with mean of ccs\n",
    "    and set values to zero if number of components above threshold is not reached\"\"\"\n",
    "    ccmatrix = np.array([tr.data for tr in ccs])\n",
    "    header = dict(sampling_rate=ccs[0].stats.sampling_rate,\n",
    "                  starttime=ccs[0].stats.starttime)\n",
    "    comp_thres = np.sum(ccmatrix > thres, axis=0) >= num_components\n",
    "    data = np.mean(ccmatrix, axis=0) * comp_thres\n",
    "    return Trace(data=data, header=header)\n",
    "\n",
    "def simf(ccs):\n",
    "    return similarity_component_thres(ccs, 0.6, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba295de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suavizado_por_convolucion(Data):\n",
    "    t = np.arange(len(Data))\n",
    "\n",
    "    #llenamos el vector de ceros\n",
    "    g = np.zeros(len(Data))\n",
    "    g[t<=500]= 1/1001\n",
    "    g[-500:] = 1/1001\n",
    "    print (g)\n",
    "\n",
    "    # Hacemos las transformadas de fourier\n",
    "    signal_tf = np.fft.fft(Data)\n",
    "    g_tf = np.fft.fft(g)\n",
    "\n",
    "    #Hacemos la convolución\n",
    "    y_tf = signal_tf * g_tf\n",
    "    cft_sv = np.fft.ifft(y_tf)\n",
    "\n",
    "    return np.real(cft_sv)\n",
    "def suavizado_señal(signal, ventana):\n",
    "    signal = pd.Series(signal)\n",
    "\n",
    "    # Definir la ventana móvil\n",
    "    window_size = ventana\n",
    "    window = signal.rolling(window_size, center=True)\n",
    "\n",
    "    # Calcular la mediana móvil\n",
    "    smooth_signal = window.median()\n",
    "    #print(len(signal), len(smooth_signal))\n",
    "    smooth_signal = np.nan_to_num(smooth_signal, nan=0.0)\n",
    "    #print(\" el valor de smooth signal en la casilla  \",1,smooth_signal[1])\n",
    "\n",
    "\n",
    "    # Calcular la desviación estándar móvil\n",
    "    std_signal = window.std()\n",
    "\n",
    "    # Identificar los outliers en la señal suavizada\n",
    "    outliers = smooth_signal[(smooth_signal < signal - 3*std_signal) | (smooth_signal > signal + 3*std_signal)]\n",
    "\n",
    "    # Encontrar los máximos y mínimos relativos en la señal suavizada\n",
    "    maximos = argrelextrema(smooth_signal, np.greater)[0]\n",
    "    minimos = argrelextrema(smooth_signal, np.less)[0]\n",
    "    extremos_relativos = np.sort(np.concatenate((maximos, minimos)))\n",
    "    extremos_relativos_vector = np.zeros(len(signal))\n",
    "\n",
    "    # Asignar los valores de smooth_signal[extremos_relativos] al vector de ceros\n",
    "    extremos_relativos_vector[extremos_relativos] = smooth_signal[extremos_relativos]\n",
    "    return smooth_signal, extremos_relativos, extremos_relativos_vector, maximos,minimos\n",
    "\n",
    "# Derivada numérica (extremos relativos)\n",
    "def  condicion_primer_orden( smooth_signal):\n",
    "    extrems = np.zeros(len(smooth_signal))\n",
    "    t = np.arange(len(smooth_signal))\n",
    "    smooth_signal = np.nan_to_num(smooth_signal, nan=0.0)\n",
    "\n",
    "    for x in t[1:-1]:\n",
    "        c = x\n",
    "        a = int(c - 1)\n",
    "        b = int(c + 1)\n",
    "        dleft = int(smooth_signal[a]) - int(smooth_signal[x])\n",
    "        dright = smooth_signal[b] - smooth_signal[x]\n",
    "        if dleft < 0 and dright < 0:\n",
    "            extrems[c] = smooth_signal[c]\n",
    "        elif dleft > 0 and dright > 0:\n",
    "            extrems[c] = smooth_signal[c]\n",
    "        else:\n",
    "            extrems[x] = 0\n",
    "    return extrems\n",
    "    \n",
    "def encontrar_extremos_relativos(smooth_signal):\n",
    "    extrems = np.zeros(len(smooth_signal))\n",
    "    t = np.arange(len(smooth_signal))\n",
    "    smooth_signal = np.nan_to_num(smooth_signal, nan=0.0)\n",
    "\n",
    "    # Calcula la derivada numérica \n",
    "    dx_Y = np.diff(smooth_signal, prepend=0, append=0)\n",
    "\n",
    "    for x in t[1:-1]:\n",
    "        # Ajuste en la condición de extremo: Cambio de signo en la derivada\n",
    "        if np.sign(dx_Y[x]) != np.sign(dx_Y[x + 1]):\n",
    "            extrems[x] = smooth_signal[x]\n",
    "\n",
    "    return extrems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030b9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculo_clusters_signal (x,y):\n",
    "    n_clusters = n_Clusters\n",
    "    kmeans = KMeans(n_clusters)\n",
    "    x_multi = np.concatenate((x,y),axis=1)\n",
    "    kmeans.fit(x_multi)\n",
    "    clusters = kmeans.fit_predict(x_multi)\n",
    "    cluster_array = []\n",
    "    for u in clusters.data:\n",
    "        cluster_array.append([u])\n",
    "\n",
    "    return cluster_array\n",
    "\n",
    "def calculo_clusters_signal_seismic_2 (x,x2,y, n__Clusters):\n",
    "    n_clusters = n__Clusters\n",
    "    kmeans = KMeans(n_clusters)\n",
    "    x_multi = np.concatenate((x,x2,y),axis=1)\n",
    "    kmeans.fit(x_multi)\n",
    "    clusters = kmeans.fit_predict(x_multi)\n",
    "    cluster_array = []\n",
    "    for u in clusters.data:\n",
    "        cluster_array.append([u])\n",
    "\n",
    "    return cluster_array\n",
    "\n",
    "def calculo_clusters_signal_seismic (x,y, n__Clusters):\n",
    "    n_clusters = n__Clusters\n",
    "    kmeans = KMeans(n_clusters)\n",
    "    x_multi = np.concatenate((x,y),axis=1)\n",
    "    kmeans.fit(x_multi)\n",
    "    clusters = kmeans.fit_predict(x_multi)\n",
    "    cluster_array = []\n",
    "    for u in clusters.data:\n",
    "        cluster_array.append([u])\n",
    "\n",
    "    return cluster_array\n",
    "    \n",
    "##============================================\n",
    "## Cálculo de estadísticas de conglomerados \n",
    "##============================================\n",
    "def  estadisticas_conglomerados( r_multi_df):\n",
    "    y_clus      = []\n",
    "    y_mean      = []\n",
    "    y_std       = []\n",
    "    y_min       = []\n",
    "    y_max       = []\n",
    "    y_median    = []\n",
    "    y_count     = []\n",
    "    y_rcount     = []\n",
    "    y_scount     = []\n",
    "    array_size  = len(r_multi_df)\n",
    "    minut_size = array_size/df/60\n",
    "    \n",
    "    for i in np.arange(n_Clusters): \n",
    "        dfd= r_multi_df[r_multi_df.c == i]\n",
    "        \n",
    "        y_clus.append([i])\n",
    "        y_mean.append([dfd.y.mean()])\n",
    "        y_std.append([dfd.y.std()])\n",
    "        y_min.append([dfd.y.min()])\n",
    "        y_max.append([dfd.y.max()])\n",
    "        y_median.append([dfd.y.median()])\n",
    "        y_count.append([dfd.y.count()])\n",
    "        y_rcount.append([dfd.y.count()/array_size])\n",
    "        y_scount.append([dfd.y.count()/array_size*minut_size])\n",
    "\n",
    "    r_multi = np.concatenate((y_clus, y_mean,y_std,y_min, y_max, y_median, y_count, y_rcount, y_scount),axis=1)\n",
    "    multi_prm = pd.DataFrame(r_multi, columns = ['c','ymean','ystd','ymin','ymax','ymedian','ycount', 'yrcount', 'yscount'] )\n",
    "\n",
    "    prm_sorted = multi_prm.sort_values(by=['ymean'])\n",
    "    prm_sorted = prm_sorted.reset_index(drop=True)\n",
    "    return(prm_sorted)\n",
    "\n",
    "def cluster_N (mul_df, Cluster):\n",
    "    c_c = prm_sorted_signal.iloc[C_idx:,0]\n",
    "    t_c    = []\n",
    "    x_c    = HDF_zeros\n",
    "    y_c    = HDF_zeros\n",
    "    y_sv_c = HDF_zeros\n",
    "    index_c =[]\n",
    "    for j in np.arange(len(HDF_zeros)):\n",
    "        t_c.append([0])\n",
    "    dfd_i   = mul_df[mul_df.c == c_c].index\n",
    "    dfd_d = mul_df[mul_df.c == c_c]\n",
    "\n",
    "    return dfd_d, dfd_i\n",
    "\n",
    "def cluster_N_extrem (mul_df, prm_sorted,C_idx,plus):\n",
    "    c_c = prm_sorted_signal.iloc[C_idx:,0]\n",
    "    t_c    = []\n",
    "    x_c    = EHZ_zeros\n",
    "    y_c    = EHZ_zeros\n",
    "    y_sv_c = EHZ_zeros\n",
    "    \n",
    "    index_c =[]\n",
    "    cond = True \n",
    "    if plus== \"=\":\n",
    "        c_c = prm_sorted_signal.iloc[C_idx,0]\n",
    "    elif plus == \"+\":\n",
    "        c_c = prm_sorted_signal.iloc[C_idx:,0]\n",
    "    elif plus == \"-\":\n",
    "        c_c = prm_sorted_signal.iloc[:C_idx,0]\n",
    "    if plus == \"+\" or plus ==\"-\":\n",
    "        dfd_i   = mul_df[mul_df['c'].isin(c_c)].index\n",
    "        dfd_d = mul_df[mul_df['c'].isin(c_c)]\n",
    "    else:\n",
    "        dfd_i   = mul_df[mul_df.c == c_c].index\n",
    "        dfd_d = mul_df[mul_df.c == c_c]\n",
    "        \n",
    "    return dfd_d, dfd_i\n",
    "\n",
    "def cluster_N_extrems (mul_df, prm_sorted,c_idx):\n",
    "    C_idx = int(c_idx)\n",
    "    seq = []\n",
    "    for x in np.arange(n_Clusters):\n",
    "        seq.append(x)\n",
    "    result = []\n",
    "    ran_in = n_Clusters-C_idx\n",
    "\n",
    "    for i in range(C_idx):\n",
    "        result.append(seq[i])\n",
    "    for i in range(ran_in,n_Clusters):\n",
    "        result.append(seq[i])\n",
    "\n",
    "    c_c = []\n",
    "    for i in prm_sorted_signal.iloc[result,0].values:\n",
    "        c_c.append(int(i))\n",
    "    #for i in prm_sorted_signal.iloc[up_l:,0].values:\n",
    "    #    c_c.append(int(i))\n",
    "        \n",
    "    #for i in prm_sorted_signal.iloc[:lo_l,0].values:\n",
    "    #    c_c.append(int(i))\n",
    "    \n",
    "    dfd_i   = mul_df[mul_df['c'].isin(c_c)].index\n",
    "    dfd_d = mul_df[mul_df['c'].isin(c_c)]\n",
    "    \n",
    "    return dfd_d, dfd_i\n",
    "    \n",
    "def cluster_N_extrems_seismic (mul_df, prm_sorted,c_idx):\n",
    "    C_idx = int(c_idx)\n",
    "    seq = []\n",
    "    for x in np.arange(n_Clusters+n_plus_Clusters):\n",
    "        seq.append(x)\n",
    "    result = []\n",
    "    ran_in = n_Clusters+n_plus_Clusters-C_idx\n",
    "\n",
    "    for i in range(C_idx):\n",
    "        result.append(seq[i])\n",
    "    for i in range(ran_in,n_Clusters):\n",
    "        result.append(seq[i])\n",
    "\n",
    "    c_c = []\n",
    "    for i in prm_sorted_signal.iloc[result,0].values:\n",
    "        c_c.append(int(i))\n",
    "    #for i in prm_sorted_signal.iloc[up_l:,0].values:\n",
    "    #    c_c.append(int(i))\n",
    "        \n",
    "    #for i in prm_sorted_signal.iloc[:lo_l,0].values:\n",
    "    #    c_c.append(int(i))\n",
    "    \n",
    "    dfd_i   = mul_df[mul_df['c'].isin(c_c)].index\n",
    "    dfd_d = mul_df[mul_df['c'].isin(c_c)]\n",
    "    return dfd_d, dfd_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_up = 600\n",
    "pick_up_to = 150\n",
    "fmin_HDF=0.5\n",
    "fmax_HDF=20\n",
    "fmin_EHZ = 5#0.5 #5 #.5\n",
    "fmax_EHZ = 15#5   #15 #7\n",
    "fmin_seismic = 0.2\n",
    "fmax_seismic = 7\n",
    "df = 50\n",
    "tiempo_entre_explosiones_min= 3\n",
    "x_Clusters = 5\n",
    "n_Clusters = 25 #29#25#19\n",
    "n_plus_Clusters = 8#0 #8\n",
    "pascal_multiplicador = 0.0002777\n",
    "dif_ini_delay = 30\n",
    "t_m = df\n",
    "cero_period = tiempo_entre_explosiones_min\n",
    "cross_treshold = .60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd94b05",
   "metadata": {},
   "source": [
    "# Procesamiento de señal sísmica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc05af-8cf2-4d99-9a36-2b123feb44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick = UTC('2022-09-17T0:00:00')\n",
    "\n",
    "\n",
    "st__HDF = read(\"GI.FG12.02.BDF.D.2022.260.mseed\")\n",
    "st__EHZ = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "\n",
    "tr_HDF = st__HDF[0]\n",
    "tr_EHZ = st__EHZ[0]\n",
    "\n",
    "tr_tr = range(0,tr_EHZ.stats.npts,pick_up)\n",
    "l_t_i = tr_EHZ.stats.starttime\n",
    "\n",
    "\n",
    "times = np.arange(tr_EHZ.times(\"utcdatetime\")[0], tr_EHZ.times(\"utcdatetime\")[-1], pick_up)\n",
    "ii = 1\n",
    "l_t_i = times[0]\n",
    "detecciones = []\n",
    "det_inicio = []\n",
    "det_final = []\n",
    "det_tr_inicio =[]\n",
    "det_tr_fin = []\n",
    "\n",
    "seismic_inicio = []\n",
    "seismic_fin    = []\n",
    "for t in times[1:]:\n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    print(\"==========================\")\n",
    "    print(ii,t)\n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    ii +=1\n",
    "    t_i = t\n",
    "    #print(t_i)\n",
    "    #print(l_t_i, t_i)\n",
    "    st_HDF_trimmed = st__HDF.copy()\n",
    "    st_EHZ_trimmed = st__EHZ.copy()\n",
    "    st_EHZ = st_EHZ_trimmed.trim(l_t_i, t_i)\n",
    "    st_HDF = st_HDF_trimmed.trim(l_t_i, t_i)\n",
    "    st_HDF = st_HDF.filter('bandpass', freqmin= fmin_HDF, freqmax=fmax_HDF, corners=4, zerophase=True)\n",
    "    st_EHZ = st_EHZ.filter('bandpass', freqmin= fmin_seismic, freqmax=fmax_seismic, corners=2, zerophase=True)\n",
    "\n",
    "    tr_HDF = st_HDF[0]\n",
    "    tr_EHZ = st_EHZ[0]\n",
    "    l_t_i =  t_i\n",
    "\n",
    "    serie  = tr_EHZ.data \n",
    "    signal = pd.Series(serie)\n",
    "    \n",
    "    ss, er, erv,s_mx,s_mn = suavizado_señal(signal,7)\n",
    "    ss2, er2, erv2,s_mx2,s_mn2 = suavizado_señal(signal,25)\n",
    "    \n",
    "\n",
    "    dist = np.diff(er)\n",
    "\n",
    "    #===========================================\n",
    "    # Derivada numérica (extremos relativos)\n",
    "    extrems = encontrar_extremos_relativos(ss)\n",
    "    extrems2 = encontrar_extremos_relativos(ss2)\n",
    "    \n",
    "    t = np.arange(len(extrems))\n",
    "    print(\"t\", t)\n",
    "    print(\"extrems\", extrems)\n",
    "    print(\"len(t)\", len(t), \"extrems\", len(extrems))\n",
    "    plt.figure(figsize=(35,15))\n",
    "    plt.plot(signal, color='#1E90FF', alpha=.5, label='Señal original', zorder=0)\n",
    "    plt.plot(ss, color='#FF4500', alpha=.5, label= \"onda suavizada\", zorder=1)\n",
    "    plt.legend(fontsize=25)\n",
    "\n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(35,15))\n",
    "    plt.plot(signal, color='#1E90FF', alpha=.5, label='Señal original', zorder=0)\n",
    "    plt.plot(ss2, color='#FF4500', alpha=.5, label= \"onda suavizada\", zorder=1)\n",
    "    plt.legend(fontsize=25)\n",
    "    \n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=30)\n",
    "    plt.yticks(fontsize=30)\n",
    "    plt.show()\n",
    "\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##                                      ##\n",
    "    ##           Clústers                   ##\n",
    "    ##                                      ##\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    t = np.arange(len(tr_EHZ.data))\n",
    "    y_array      = []\n",
    "    y_sv_array   = []\n",
    "    x_array      = []\n",
    "    x2_array     = []\n",
    "    t_array      = []\n",
    "    for r in extrems.data:\n",
    "        x_array.append([r])\n",
    "\n",
    "    for r2 in extrems2.data:\n",
    "        x2_array.append([r2])\n",
    "        \n",
    "    for s in tr_EHZ.data:\n",
    "        y_array.append([s])\n",
    "    for s in ss:\n",
    "        y_sv_array.append([s])\n",
    "\n",
    "    for u in t:\n",
    "        t_array.append([u])\n",
    "\n",
    "    n_clusters = n_Clusters + n_plus_Clusters\n",
    "    kmeans = KMeans(n_clusters)\n",
    "    \n",
    "    cluster_array = calculo_clusters_signal_seismic_2(x_array,x2_array,y_array,n_clusters)\n",
    "    x_multi           = np.concatenate((t_array,x_array,y_array,y_sv_array, cluster_array),axis=1)\n",
    "    multi_df          = pd.DataFrame(x_multi, columns = ['t','x','y','y_sv','c'] )\n",
    "    prm_sorted_signal = estadisticas_conglomerados(multi_df)\n",
    "    \n",
    "##===================================================\n",
    "## Optimización de detecciones descontando outliers\n",
    "##===================================================\n",
    "    k = int((n_clusters - 1) / 2)\n",
    "\n",
    "    # Generar los valores de la secuencia en un rango de 1 a n\n",
    "    sequence = list(range(1, k + 1))\n",
    "\n",
    "    # Ordenar la secuencia de mayor a menor\n",
    "    sequence.sort(reverse=True)\n",
    "\n",
    "    t_distancia_avg = []\n",
    "    t_conteo        = []\n",
    "    t_cluster       = []\n",
    "\n",
    "\n",
    "    # Iterar en un ciclo for\n",
    "    for x_clusters in sequence:\n",
    "        t_inicio        = []\n",
    "        t_inicio_val    = []\n",
    "        t_final         = []\n",
    "        t_final_val     = []\n",
    "        t_distancia     = []\n",
    "        \n",
    "        c_df, c_idx = cluster_N_extrems_seismic (multi_df, prm_sorted_signal,x_clusters)\n",
    "        t = c_df.t.values\n",
    "        y = c_df.y.values\n",
    "    \n",
    "        last_t = t[0]\n",
    "        very_last = t[0]\n",
    "        for ji in t[1:]:\n",
    "            if (ji - very_last) >= t_m*cero_period and (very_last - last_t) <= t_m:\n",
    "                last_t = ji\n",
    "                very_last_t = ji\n",
    "            elif (ji - very_last) >= t_m*cero_period and (very_last - last_t) > t_m:\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append(y_array[int(last_t)])\n",
    "                t_final.append([very_last])\n",
    "                t_final_val.append(y_array[int(very_last)])\n",
    "                t_distancia.append(abs(last_t-very_last))\n",
    "\n",
    "                last_t = ji\n",
    "                if ji == t[-1]:\n",
    "                    t_inicio.append([last_t])\n",
    "                    t_inicio_val.append([y_array[int(last_t)]])\n",
    "                    t_final.append([ji])\n",
    "                    t_final_val.append(y_array[int(ji)])\n",
    "                    t_distancia.append(abs(last_t-ji))\n",
    "                    break\n",
    "            if ji == t[-1]:\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append([y_array[int(last_t)]])\n",
    "                t_final.append([ji])\n",
    "                t_final_val.append(y_array[int(ji)])\n",
    "                t_distancia.append(abs(last_t-ji))\n",
    "                break\n",
    "            very_last = ji\n",
    "            \n",
    "        t_conteo.append(len(t_final))\n",
    "        t_cluster.append(x_clusters)\n",
    "        t_distancia_avg.append(np.mean(t_distancia))\n",
    "        print(x_clusters, len(t_final),np.mean(t_distancia)/t_m )\n",
    "        \n",
    "    t_conteos_max = np.argmax(t_conteo)\n",
    "    \n",
    "    for i in range(len(t_conteo)):\n",
    "        if all(x == t_conteo[0] for x in t_conteo):\n",
    "            print(\" aplico 1\")\n",
    "            max_index = round(len(t_conteo)/2, 0)\n",
    "            break\n",
    "\n",
    "        if (t_cluster[i] == t_cluster[t_conteos_max] \n",
    "            and   t_conteo[t_conteos_max] <=20 \n",
    "            and (t_conteo[t_conteos_max]-t_conteo[t_conteos_max+1])>5\n",
    "            and t_conteo[i-1]!=1\n",
    "            and t_conteo[i]>1 \n",
    "            and t_conteo[i-1]==1 \n",
    "            and i <=1\n",
    "           ):\n",
    "            print(\" aplico 2\")\n",
    "            max_index = t_cluster[i]\n",
    "            break\n",
    "                    \n",
    "        if i == len(t_conteo) - 1:\n",
    "            print(\" aplico 3\")\n",
    "            max_index = t_cluster[i-1]\n",
    "            break\n",
    "                \n",
    "        if (i < len(t_conteo)-3 and i >=2\n",
    "            and t_conteo[i-2] ==1\n",
    "            and t_conteo[i-1] >1 \n",
    "           ):\n",
    "            max_index = t_cluster[i]\n",
    "            if t_conteo[max_index] >20:\n",
    "                print(\" aplico 4\")\n",
    "                max_index = t_cluster[i+1]\n",
    "            elif t_distancia_avg[max_index] > 45 and t_distancia_avg[max_index] > t_distancia_avg[max_index+1]:\n",
    "                print(\" aplico 5\")\n",
    "                if i >1 and t_conteo[i-1] ==1:\n",
    "                    print(\" aplico 5.1\")\n",
    "                    max_index=t_cluster[i+2]\n",
    "                elif t_conteo[i+1] >1 and t_conteo[i+2]<20 and t_distancia_avg[i+1]> t_distancia_avg[i+2]:\n",
    "                    print(\"aplico 5.2\")\n",
    "                    max_index=t_cluster[i+2]\n",
    "                else:\n",
    "                    print(\" aplico 5.3\")\n",
    "                    max_index=t_cluster[i+3]\n",
    "            else:\n",
    "            #    print(\" aplico 6\")\n",
    "            #    max_index = t_cluster[i]\n",
    "                if t_distancia_avg[i] >45:\n",
    "                    print(\"aplico 6.1\")\n",
    "                    max_index = t_cluster[i+1]\n",
    "                else:\n",
    "                    print(\"aplico 6.2\")\n",
    "                    max_index = t_cluster[i]\n",
    "            \n",
    "            break       \n",
    "\n",
    "    print(\"El índice del mayor valor que no es un valor atípico es:\", max_index)\n",
    "##===================================================\n",
    "## Este es el fin de la optimización sin outliers\n",
    "##===================================================\n",
    "    \n",
    "    c_df, c_idx = cluster_N_extrems_seismic (multi_df, prm_sorted_signal,max_index)\n",
    "    \n",
    "    ##=================================================\n",
    "    ## Grafico de conglomerados de la onda original\n",
    "    ##=================================================\n",
    "    print(prm_sorted_signal.c)\n",
    "    print(\"Gráfico de conglomerados de la onda original\")\n",
    "    plt.figure(figsize=(30,15))\n",
    "    plt.scatter(t_array,y_array, c=cluster_array, cmap='rainbow')\n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    plt.show()\n",
    "    \n",
    "    t = c_df.t.values\n",
    "    y = c_df.y.values\n",
    "\n",
    "    y_min =np.min(y)\n",
    "    cero_count =0\n",
    "    t_m = df\n",
    "    cero_period = tiempo_entre_explosiones_min\n",
    "    t_inicio     = []\n",
    "    t_inicio_val = []\n",
    "    t_final      = []\n",
    "    t_final_val  = []\n",
    "    t_distancia  = []\n",
    "    t_cero = t[0]\n",
    "    t_last =int(t_cero)\n",
    "    \n",
    "    last_t = t[0]\n",
    "    very_last = t[0]\n",
    "    count_ponts = 0\n",
    "    for ji in t[1:]:\n",
    "        if (ji - very_last) >= t_m*cero_period and (very_last - last_t) <= t_m:\n",
    "            last_t = ji\n",
    "            very_last_t = ji\n",
    "        elif (ji - very_last) >= t_m*cero_period and (very_last - last_t) > t_m:\n",
    "\n",
    "            t_inicio.append(last_t)\n",
    "\n",
    "            t_inicio_val.append(y_array[int(last_t)])\n",
    "            t_final.append(very_last)\n",
    "            t_final_val.append(y_array[int(very_last)])\n",
    "            last_t = ji\n",
    "            if ji == t[-1]:\n",
    "                t_inicio.append(last_t)\n",
    "                t_inicio_val.append(y_array[int(last_t)])\n",
    "                t_final.append(ji)\n",
    "                t_final_val.append(y_array[int(ji)])\n",
    "                break\n",
    "        if ji == t[-1]:\n",
    "            t_inicio.append(last_t)\n",
    "            t_inicio_val.append(y_array[int(last_t)])\n",
    "            t_final.append(ji)\n",
    "            t_final_val.append(y_array[int(ji)])\n",
    "            break\n",
    "        very_last = ji\n",
    "            \n",
    "    plt.figure(figsize=(30,15))\n",
    "    plt.scatter(t_array,y_array,c='g')\n",
    "    plt.scatter(c_df.t,c_df.y, c='orange')\n",
    "    plt.scatter(t_inicio,t_inicio_val,c ='r')\n",
    "    plt.scatter(t_final,t_final_val, c = 'b')\n",
    "\n",
    "\n",
    "    # Agregar las barras verticales para indicar el inicio y fin del evento\n",
    "    for inicio, fin in zip(t_inicio, t_final):\n",
    "        plt.axvline(x=inicio, color='r', linestyle='--')\n",
    "        plt.axvline(x=fin, color='g', linestyle='--')\n",
    "\n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "\n",
    "    # Mostrar el plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "    ##\n",
    "    ## Aquí  inicia el análisis de intervalos\n",
    "    ##\n",
    "    ##################################################################################\n",
    "    t_times = []\n",
    "    for i in range(len(t_inicio[1:])):\n",
    "        t_times.append(t_inicio[i])\n",
    "        t_times.append(t_final[i])\n",
    "\n",
    "    tr_times = []\n",
    "    tr_time_ini =[]\n",
    "    tr_time_fin =[]\n",
    "    explo_count = 0\n",
    "    explode = []\n",
    "    \n",
    "    for v in tr_EHZ.times(\"utcdatetime\")  :\n",
    "        tr_times.append(v)\n",
    "\n",
    "    for i in range(len(t_inicio)):#[1:])):\n",
    "        tini = t_inicio[i]\n",
    "        tfin = t_final [i]\n",
    "        if tini < 0:\n",
    "            tini = 0\n",
    "        if tfin >= len(tr_times):\n",
    "            tfin = len(tr_times)-1\n",
    "        tr_time_ini.append(tr_times[int(tini)])\n",
    "        tr_time_fin.append(tr_times[int(tfin)])\n",
    "        explo_count +=1\n",
    "        explode.append(explo_count-1)\n",
    "     \n",
    "    explode_2d = np.expand_dims(explode, axis=1)\n",
    "    tr_time_ini_2d = np.expand_dims(tr_time_ini, axis=1)\n",
    "    tr_time_fin_2d = np.expand_dims(tr_time_fin, axis=1)\n",
    "\n",
    "    the_times = np.concatenate((explode_2d,tr_time_ini_2d,tr_time_fin_2d),axis=1)\n",
    "    EHZ_times = pd.DataFrame(the_times, columns = ['explode','time_start','time_end'] )\n",
    "    it = 0\n",
    "        \n",
    "    for ix in range(len(EHZ_times)):\n",
    "        time_INI  = EHZ_times.iloc[ix,1]    \n",
    "        time_FIN  = EHZ_times.iloc[ix,2]\n",
    "        print (time_INI,time_FIN,time_FIN-time_INI)\n",
    "        seismic_inicio.append(time_INI)\n",
    "        seismic_fin.append(time_FIN)\n",
    "       \n",
    "\n",
    "    \n",
    "            \n",
    "    if tr_time_ini != [] and tr_time_fin !=[]:\n",
    "        for dti in tr_time_ini:\n",
    "            det_tr_inicio.append(dti)\n",
    "        for dtf in tr_time_fin:\n",
    "            det_tr_fin.append(dtf)\n",
    "\n",
    "        \n",
    "det_tr_seismic_inicio = det_tr_inicio\n",
    "det_tr_seismic_fin    = det_tr_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65108ca7",
   "metadata": {},
   "source": [
    "# Procesamiento de señal acústica registrada por el sismómetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbad4a82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pick = UTC('2022-09-17T0:00:00')\n",
    "\n",
    "st__HDF = read(\"GI.FG12.02.BDF.D.2022.260.mseed\")\n",
    "st__EHZ = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "\n",
    "tr_HDF = st__HDF[0]\n",
    "tr_EHZ = st__EHZ[0]\n",
    "\n",
    "tr_tr = range(0,tr_EHZ.stats.npts,pick_up)\n",
    "l_t_i = tr_EHZ.stats.starttime\n",
    "\n",
    "\n",
    "times = np.arange(tr_EHZ.times(\"utcdatetime\")[0], tr_EHZ.times(\"utcdatetime\")[-1], pick_up)\n",
    "ii = 1\n",
    "l_t_i = times[0]\n",
    "detecciones = []\n",
    "det_inicio = []\n",
    "det_final = []\n",
    "det_tr_inicio =[]\n",
    "det_tr_fin = []\n",
    "for t in times[1:]:\n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    print(\"==========================\")\n",
    "    print(ii,t)\n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    ii +=1\n",
    "    t_i = t\n",
    "    #print(t_i)\n",
    "    #print(l_t_i, t_i)\n",
    "    st_HDF_trimmed = st__HDF.copy()\n",
    "    st_EHZ_trimmed = st__EHZ.copy()\n",
    "    st_EHZ = st_EHZ_trimmed.trim(l_t_i, t_i)\n",
    "    st_HDF = st_HDF_trimmed.trim(l_t_i, t_i)\n",
    "    st_HDF = st_HDF.filter('bandpass', freqmin= fmin_HDF, freqmax=fmax_HDF, corners=2, zerophase=True)\n",
    "    st_EHZ = st_EHZ.filter('bandpass', freqmin= fmin_EHZ, freqmax=fmax_EHZ, corners=2, zerophase=True)\n",
    "    tr_HDF = st_HDF[0]\n",
    "    tr_EHZ = st_EHZ[0]\n",
    "    l_t_i =  t_i\n",
    "\n",
    "    serie  = tr_EHZ.data \n",
    "    signal = pd.Series(serie)\n",
    "    ss, er, erv,s_mx,s_mn = suavizado_señal(signal,51)\n",
    "    dist = np.diff(er)\n",
    "    extrems = encontrar_extremos_relativos(ss)\n",
    "    t = np.arange(len(extrems))\n",
    "\n",
    "    plt.figure(figsize=(35,15))\n",
    "    plt.plot(signal, color='#1E90FF', label='Señal original', zorder=0)\n",
    "    plt.scatter(t,extrems, c='#32CD32',label=\"valores extremos\", zorder=2)\n",
    "    plt.plot(ss, color='#FF4500', label= \"onda suavizada\", zorder=1)\n",
    "    plt.legend(fontsize=25)\n",
    "    \n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    plt.show()\n",
    "    \n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##                                      ##\n",
    "    ##           Clústers                   ##\n",
    "    ##                                      ##\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    t = np.arange(len(tr_EHZ.data))\n",
    "    y_array      = []\n",
    "    y_sv_array   = []\n",
    "    x_array      = []\n",
    "    t_array      = []\n",
    "    for r in extrems.data:\n",
    "        x_array.append([r])\n",
    "\n",
    "    for s in tr_EHZ.data:\n",
    "        y_array.append([s])\n",
    "    for s in ss:\n",
    "        y_sv_array.append([s])\n",
    "\n",
    "    for u in t:\n",
    "        t_array.append([u])\n",
    "\n",
    "    n_clusters = n_Clusters\n",
    "    kmeans = KMeans(n_Clusters)\n",
    "    \n",
    "    cluster_array     = calculo_clusters_signal(x_array,y_array)\n",
    "    x_multi           = np.concatenate((t_array,x_array,y_array,y_sv_array, cluster_array),axis=1)\n",
    "    multi_df          = pd.DataFrame(x_multi, columns = ['t','x','y','y_sv','c'] )\n",
    "    prm_sorted_signal = estadisticas_conglomerados(multi_df)\n",
    "    \n",
    "##===================================================\n",
    "## Optimización de detecciones descontando outliers\n",
    "##===================================================\n",
    "    k = int((n_clusters - 1) / 2)\n",
    "\n",
    "    # Generar los valores de la secuencia en un rango de 1 a n\n",
    "    sequence = list(range(1, k + 1))\n",
    "\n",
    "    # Ordenar la secuencia de mayor a menor\n",
    "    sequence.sort(reverse=True)\n",
    "\n",
    "    t_distancia_avg = []\n",
    "    t_conteo        = []\n",
    "    t_cluster       = []\n",
    "\n",
    "\n",
    "    # Iterar en un ciclo for\n",
    "    for x_clusters in sequence:\n",
    "        t_inicio        = []\n",
    "        t_inicio_val    = []\n",
    "        t_final         = []\n",
    "        t_final_val     = []\n",
    "        t_distancia     = []\n",
    "        \n",
    "        c_df, c_idx = cluster_N_extrems (multi_df, prm_sorted_signal,x_clusters)\n",
    "        t = c_df.t.values\n",
    "        y = c_df.y.values\n",
    "\n",
    "    \n",
    "        last_t = t[0]\n",
    "        very_last = t[0]\n",
    "        for ji in t[1:]:\n",
    "            if (ji - very_last) >= t_m*cero_period:\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append(y_array[int(last_t)])\n",
    "                t_final.append([very_last])\n",
    "                t_final_val.append(y_array[int(very_last)])\n",
    "                t_distancia.append(abs(last_t-very_last))\n",
    "\n",
    "                last_t = ji\n",
    "                if ji == t[-1]:\n",
    "                    t_inicio.append([last_t])\n",
    "                    t_inicio_val.append([y_array[int(last_t)]])\n",
    "                    t_final.append([ji])\n",
    "                    t_final_val.append(y_array[int(ji)])\n",
    "                    t_distancia.append(abs(last_t-ji))\n",
    "                    break\n",
    "            if ji == t[-1]:\n",
    "                #print('hay que hacer otro corte de emergencia')\n",
    "                #print('los límites del otro intervalo de emergencia son', last_t, ji)\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append([y_array[int(last_t)]])\n",
    "                t_final.append([ji])\n",
    "                t_final_val.append(y_array[int(ji)])\n",
    "                t_distancia.append(abs(last_t-ji))\n",
    "                break\n",
    "            very_last = ji\n",
    "        t_conteo.append(len(t_final))\n",
    "        t_cluster.append(x_clusters)\n",
    "        t_distancia_avg.append(np.mean(t_distancia))\n",
    "    \n",
    "    \n",
    "    # Calcular el percentil 90\n",
    "    #PCT9 = math.ceil(np.percentile(t_conteo,90))\n",
    "    #Q1 = np.percentile(t_conteo,25)\n",
    "    #Q3 = np.percentile(t_conteo,75)\n",
    "    #IQR = Q3-Q1\n",
    "    outliers = []\n",
    "    no_hay_conteos = False\n",
    "    t_conteos_max = np.argmax(t_conteo)\n",
    "    \n",
    "    for i in range(len(t_conteo)):\n",
    "        if all(x == t_conteo[0] for x in t_conteo):\n",
    "            #print(\"aplico 1\")\n",
    "            max_index = round(len(t_conteo)/2, 0)\n",
    "            break\n",
    "\n",
    "        if i >=1:\n",
    "            if t_conteo[i]>1 and t_conteo[i-1]==1:\n",
    "                if t_cluster[i] == t_cluster[t_conteos_max] and t_conteo[i-1] ==1 and t_conteo[1-2]== 1 and i < len(t_conteo)-3:\n",
    "                    #print(\"aplico 2\")\n",
    "                    max_index = t_cluster[i+1]\n",
    "                    break\n",
    "                    \n",
    "                if t_cluster[i] == t_cluster[t_conteos_max] and   t_conteo[t_conteos_max] <=20 and (t_conteo[t_conteos_max]-t_conteo[t_conteos_max+1])>5:\n",
    "                    #print(\"aplico 3\")\n",
    "                    max_index = t_cluster[i]\n",
    "                    break\n",
    "                    \n",
    "                if i == len(t_conteo) - 1:\n",
    "                    #print(\"aplico 4\")\n",
    "                    max_index = t_cluster[i-1]\n",
    "                    break\n",
    "                elif i < len(t_conteo)-3:\n",
    "                    if t_cluster[i+1] == t_cluster[t_conteos_max] and t_conteo[t_conteos_max] <=20:\n",
    "                        #print(\"aplico 5\")\n",
    "                        max_index = t_cluster[i+1]\n",
    "                    else:\n",
    "                        #print(\"aplico 6\")\n",
    "                        max_index = t_cluster[i+2]\n",
    "                    break            \n",
    "        \n",
    "\n",
    "\n",
    "##===================================================\n",
    "## Este es el fin de la iptimización sin outliers\n",
    "##===================================================\n",
    "    c_df, c_idx = cluster_N_extrems (multi_df, prm_sorted_signal,max_index)\n",
    "    \n",
    "    ##=================================================\n",
    "    ## Grafico de conglomerados de la onda original\n",
    "    ##=================================================\n",
    "    print(prm_sorted_signal.c)\n",
    "    print(\"Gráfico de conglomerados de la onda original\")\n",
    "    plt.figure(figsize=(30,15))\n",
    "    plt.scatter(t_array,y_array, c=cluster_array, cmap='rainbow')\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    \n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    plt.show()\n",
    "    \n",
    "    t = c_df.t.values\n",
    "    y = c_df.y.values\n",
    "\n",
    "    y_min =np.min(y)\n",
    "    cero_count =0\n",
    "    t_m = df\n",
    "    cero_period = tiempo_entre_explosiones_min\n",
    "    t_inicio     = []\n",
    "    t_inicio_val = []\n",
    "    t_final      = []\n",
    "    t_final_val  = []\n",
    "    t_distancia  = []\n",
    "    t_cero = t[0]\n",
    "    t_last =int(t_cero)\n",
    "    \n",
    "    last_t = t[0]\n",
    "    very_last = t[0]\n",
    "    for ji in t[1:]:\n",
    "        if (ji - very_last) >= t_m*cero_period:\n",
    "            t_inicio.append([last_t])\n",
    "            t_inicio_val.append(y_array[int(last_t)])\n",
    "            t_final.append([very_last])\n",
    "            t_final_val.append(y_array[int(very_last)])\n",
    "            last_t = ji\n",
    "            if ji == t[-1]:\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append([y_array[int(last_t)]])\n",
    "                t_final.append([ji])\n",
    "                t_final_val.append(y_array[int(ji)])\n",
    "                break\n",
    "        if ji == t[-1]:\n",
    "            t_inicio.append([last_t])\n",
    "            t_inicio_val.append([y_array[int(last_t)]])\n",
    "            t_final.append([ji])\n",
    "            t_final_val.append(y_array[int(ji)])\n",
    "            break\n",
    "        very_last = ji\n",
    "                \n",
    "    tremores= False\n",
    "    for j in np.arange(len(t_final)):\n",
    "        t_distancia.append((t_final[j][0]-t_inicio[j][0])/t_m/60)\n",
    "        if (t_final[j][0]-t_inicio[j][0])/t_m/60 >1.5:\n",
    "            tremores = True\n",
    "\n",
    "\n",
    "    print(\"Distancias\",t_distancia)\n",
    "    print(\"inicio\",t_inicio)\n",
    "    print(\"final\",t_final)  \n",
    " \n",
    "    plt.figure(figsize=(35,15))\n",
    "    plt.scatter(t_array,y_array,c='g')\n",
    "    plt.scatter(c_df.t,c_df.y, c='orange')\n",
    "\n",
    "    # Agregar las barras verticales para indicar el inicio y fin del evento\n",
    "    for inicio, fin in zip(t_inicio, t_final):\n",
    "        plt.axvline(x=inicio, color='r', linestyle='--')\n",
    "        plt.axvline(x=fin, color='g', linestyle='--')\n",
    "\n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "\n",
    "    # Mostrar el plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    ##################################################################################\n",
    "    ##\n",
    "    ## Aquí  inicia el análisis de correlación cruzada\n",
    "    ##\n",
    "    ##################################################################################\n",
    "    t_times = []\n",
    "    for i in range(len(t_inicio[1:])):\n",
    "        t_times.append(t_inicio[i])\n",
    "        t_times.append(t_final[i])\n",
    "\n",
    "    stream = st_EHZ\n",
    "    stream += st_HDF\n",
    "    templates = []\n",
    "    template_names = []\n",
    "    tr_times = []\n",
    "    tr_time_ini =[]\n",
    "    tr_time_fin =[]\n",
    "    explo_count = 0\n",
    "    explode = []\n",
    "    \n",
    "    for v in tr_EHZ.times(\"utcdatetime\")  :\n",
    "        tr_times.append(v)\n",
    "    \n",
    "    for i in range(len(t_inicio)):#[1:])):\n",
    "        tini = t_inicio[i][0]\n",
    "        tfin = t_final [i][0]\n",
    "        if tini < 0:\n",
    "            tini = 0\n",
    "        if tfin >= len(tr_times):\n",
    "            tfin = len(tr_times)-1\n",
    "        tr_time_ini.append(tr_times[int(tini)])\n",
    "        tr_time_fin.append(tr_times[int(tfin)])\n",
    "        explo_count +=1\n",
    "        explode.append([explo_count-1])\n",
    "     \n",
    "    tr_time_ini_2d = np.expand_dims(tr_time_ini, axis=1)\n",
    "    tr_time_fin_2d = np.expand_dims(tr_time_fin, axis=1)\n",
    "\n",
    "    the_times = np.concatenate((explode,tr_time_ini_2d,tr_time_fin_2d),axis=1)\n",
    "    EHZ_times = pd.DataFrame(the_times, columns = ['explode','time_start','time_end'] )\n",
    "    it = 0\n",
    "    \n",
    "    for ix in range(len(EHZ_times)):\n",
    "        time_INI  = EHZ_times.iloc[ix,1]    \n",
    "        time_FIN  = EHZ_times.iloc[ix,2]\n",
    "        print (time_INI,time_FIN,time_FIN-time_INI)\n",
    "            \n",
    "    if tr_time_ini != [] and tr_time_fin !=[]:\n",
    "        for dti in tr_time_ini:\n",
    "            det_tr_inicio.append(dti)\n",
    "        for dtf in tr_time_fin:\n",
    "            det_tr_fin.append(dtf)\n",
    "\n",
    "det_tr_EHZ_inicio = det_tr_inicio\n",
    "det_tr_EHZ_fin    = det_tr_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1e741",
   "metadata": {},
   "source": [
    "# Procesamiento de señal acústica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56bae9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pick = UTC('2022-09-17T0:00:00')\n",
    "\n",
    "tiempo_entre_explosiones_min=10\n",
    "\n",
    "st__HDF = read(\"GI.FG12.02.BDF.D.2022.260.mseed\")\n",
    "st__EHZ = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "\n",
    "tr_HDF = st__HDF[0]\n",
    "tr_EHZ = st__EHZ[0]\n",
    "\n",
    "time_relative = tr_HDF.stats.npts/tr_HDF.stats.sampling_rate\n",
    "tr_tr = range(0,tr_HDF.stats.npts,pick_up)\n",
    "l_t_i = tr_HDF.stats.starttime\n",
    "\n",
    "\n",
    "times = np.arange(tr_HDF.times(\"utcdatetime\")[0], tr_HDF.times(\"utcdatetime\")[-1], pick_up)\n",
    "ii = 1\n",
    "l_t_i = times[0]\n",
    "detecciones = []\n",
    "det_inicio = []\n",
    "det_final = []\n",
    "det_tr_inicio =[]\n",
    "det_tr_fin = []\n",
    "t_m = df\n",
    "cero_period = tiempo_entre_explosiones_min\n",
    "    \n",
    "for t in times[1:]:\n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    print(\"==========================\")\n",
    "    print(ii,t)\n",
    "    print(\" \") \n",
    "    print(\" \") \n",
    "    ii +=1\n",
    "    t_i = t\n",
    "\n",
    "    st_HDF_trimmed = st__HDF.copy()\n",
    "    st_EHZ_trimmed = st__EHZ.copy()\n",
    "    st_EHZ = st_EHZ_trimmed.trim(l_t_i, t_i)\n",
    "    st_HDF = st_HDF_trimmed.trim(l_t_i, t_i)\n",
    "    st_HDF = st_HDF.filter('bandpass', freqmin= fmin_HDF, freqmax=fmax_HDF, corners=2, zerophase=True)\n",
    "    st_EHZ = st_EHZ.filter('bandpass', freqmin= fmin_EHZ, freqmax=fmax_EHZ, corners=2, zerophase=True)\n",
    "    tr_HDF = st_HDF[0]\n",
    "    tr_EHZ = st_EHZ[0]\n",
    "    l_t_i =  t_i\n",
    "\n",
    "    serie  = tr_HDF.data \n",
    "    signal = pd.Series(serie)\n",
    "    ss, er, erv,s_mx,s_mn = suavizado_señal(signal,51)\n",
    "\n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.plot(signal, label='Señal original')\n",
    "    plt.plot(ss, label='Señal suavizada')\n",
    "    plt.legend(fontsize=25)\n",
    "    \n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    plt.show()\n",
    "\n",
    "    dist = np.diff(er)\n",
    "\n",
    "    extrems = encontrar_extremos_relativos(ss)\n",
    "    t = np.arange(len(extrems))\n",
    "    plt.figure(figsize=(35,15))\n",
    "    plt.plot(signal, color='#1E90FF', label='Señal original', zorder=0)\n",
    "    plt.scatter(t,extrems, c='#32CD32',label=\"valores extremos\", zorder=2)\n",
    "    plt.plot(ss, color='#FF4500', label= \"onda suavizada\", zorder=1)\n",
    "    plt.legend(fontsize=25)\n",
    "    \n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    plt.show()\n",
    "    \n",
    "    ##########################################\n",
    "    ##########################################\n",
    "    ##                                      ##\n",
    "    ##           Clústers                   ##\n",
    "    ##                                      ##\n",
    "    ##########################################\n",
    "    ##########################################\n",
    "\n",
    "    t = np.arange(len(tr_HDF.data))\n",
    "    y_array      = []\n",
    "    y_sv_array   = []\n",
    "    x_array      = []\n",
    "    t_array      = []\n",
    "    for r in extrems.data:\n",
    "        x_array.append([r])\n",
    "\n",
    "    for s in tr_HDF.data:\n",
    "        y_array.append([s])\n",
    "    for s in ss:\n",
    "        y_sv_array.append([s])\n",
    "\n",
    "    for u in t:\n",
    "        t_array.append([u])\n",
    "\n",
    "    n_clusters = n_Clusters\n",
    "    kmeans = KMeans(n_Clusters)\n",
    "    \n",
    "    cluster_array     = calculo_clusters_signal(x_array,y_array)\n",
    "    x_multi           = np.concatenate((t_array,x_array,y_array,y_sv_array, cluster_array),axis=1)\n",
    "    multi_df          = pd.DataFrame(x_multi, columns = ['t','x','y','y_sv','c'] )\n",
    "    prm_sorted_signal = estadisticas_conglomerados(multi_df)\n",
    "    \n",
    "    c_c = prm_sorted_signal.c[7]\n",
    "    \n",
    "##===================================================\n",
    "## Optimización de detecciones descontando outliers\n",
    "##===================================================\n",
    "    k = int((n_clusters - 1) / 2)\n",
    "\n",
    "    # Generar los valores de la secuencia en un rango de 1 a n\n",
    "    sequence = list(range(1, k + 1))\n",
    "\n",
    "    # Ordenar la secuencia de mayor a menor\n",
    "    sequence.sort(reverse=True)\n",
    "\n",
    "    t_distancia_avg = []\n",
    "    t_conteo        = []\n",
    "    t_cluster       = []\n",
    "\n",
    "    # Iterar en un ciclo for\n",
    "    for x_clusters in sequence:\n",
    "        t_inicio        = []\n",
    "        t_inicio_val    = []\n",
    "        t_final         = []\n",
    "        t_final_val     = []\n",
    "        t_distancia     = []\n",
    "        c_df, c_idx = cluster_N_extrems (multi_df, prm_sorted_signal,x_clusters)\n",
    "        t = c_df.t.values\n",
    "        y = c_df.y.values\n",
    "\n",
    "    \n",
    "        last_t = t[0]\n",
    "        very_last = t[0]\n",
    "        for ji in t[1:]:\n",
    "            if (ji - very_last) >= t_m*cero_period:\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append(y_array[int(last_t)])\n",
    "                t_final.append([very_last])\n",
    "                t_final_val.append(y_array[int(very_last)])\n",
    "                t_distancia.append(abs(last_t-very_last))\n",
    "\n",
    "                last_t = ji\n",
    "                if ji == t[-1]:\n",
    "                    t_inicio.append([last_t])\n",
    "                    t_inicio_val.append([y_array[int(last_t)]])\n",
    "                    t_final.append([ji])\n",
    "                    t_final_val.append(y_array[int(ji)])\n",
    "                    t_distancia.append(abs(last_t-ji))\n",
    "                    break\n",
    "            if ji == t[-1]:\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append([y_array[int(last_t)]])\n",
    "                t_final.append([ji])\n",
    "                t_final_val.append(y_array[int(ji)])\n",
    "                t_distancia.append(abs(last_t-ji))\n",
    "                break\n",
    "            very_last = ji\n",
    "        t_conteo.append(len(t_final))\n",
    "        t_cluster.append(x_clusters)\n",
    "        t_distancia_avg.append(np.mean(t_distancia))\n",
    "        print(x_clusters, len(t_final),np.mean(t_distancia) )\n",
    "    \n",
    "    \n",
    "    # Calcular el percentil 90\n",
    "    PCT9 = math.ceil(np.percentile(t_conteo,90))\n",
    "    Q1 = np.percentile(t_conteo,25)\n",
    "    Q3 = np.percentile(t_conteo,75)\n",
    "    IQR = Q3-Q1\n",
    "    outliers = []\n",
    "    no_hay_conteos = False\n",
    "    t_conteos_max = np.argmax(t_conteo)\n",
    "    for i in range(len(t_conteo)):\n",
    "        if all(x == t_conteo[0] for x in t_conteo):\n",
    "            #print(\"aplico 1\")\n",
    "            max_index = round(len(t_conteo)/2, 0)\n",
    "            break  \n",
    "        if i >=1:\n",
    "            if t_conteo[i]>1 and t_conteo[i-1]==1:\n",
    "                \n",
    "                if t_conteos_max < len(t_conteo)-1:\n",
    "                    if  t_cluster[i] == t_cluster[t_conteos_max] and   t_conteo[t_conteos_max] <=20 and (t_conteo[t_conteos_max]-t_conteo[t_conteos_max+1])>5:\n",
    "               #         print(\"aplico 2\")\n",
    "                        if  i> 1:\n",
    "               #             print(\"aplico 2.1\")\n",
    "                            max_index = t_cluster[i]\n",
    "                        else:\n",
    "               #             print(\"aplico 2.2\")\n",
    "                            max_index = t_cluster[i+1]\n",
    "                        break\n",
    "                    \n",
    "                if i == len(t_conteo) - 1:\n",
    "               #     print(\"aplico 3\")\n",
    "                    max_index = t_cluster[i-1]\n",
    "                    break\n",
    "        if (i < len(t_conteo)-3 and i >=2\n",
    "            and t_conteo[i-2] ==1\n",
    "            and t_conteo[i-1] >1 \n",
    "           ):\n",
    "           # print(\"aplico 4\")\n",
    "            max_index = t_cluster[i]\n",
    "            if t_conteo[max_index] >20:\n",
    "           #     print(\"aplico 5\")\n",
    "                max_index = t_cluster[i+1]\n",
    "            elif t_distancia_avg[max_index] > 45 and t_distancia_avg[max_index] > t_distancia_avg[max_index+1]:\n",
    "            #    print(\"aplico 6\")\n",
    "                max_index=t_cluster[i+1]\n",
    "            else:\n",
    "             #   print(\"aplico 7\")\n",
    "                max_index = t_cluster[i]\n",
    "            \n",
    "            break \n",
    "\n",
    "    print(\"El índice del mayor valor que no es un valor atípico es:\", max_index)\n",
    "##===================================================\n",
    "## Este es el fin de la iptimización sin outliers\n",
    "##===================================================\n",
    "\n",
    "    c_df, c_idx = cluster_N_extrems (multi_df, prm_sorted_signal,max_index)\n",
    "\n",
    "    ##=================================================\n",
    "    ## Grafico de conglomerados de la onda original\n",
    "    ##=================================================\n",
    "    print(\"Gráfico de conglomerados de la onda original\")\n",
    "    plt.figure(figsize=(30,15))\n",
    "    plt.scatter(t_array,y_array, c=cluster_array, cmap='rainbow')\n",
    "\n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "    \n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    plt.show()\n",
    "    \n",
    "    t = c_df.t.values\n",
    "    y = c_df.y.values\n",
    "\n",
    "    y_min =np.min(y)\n",
    "    cero_count =0\n",
    "    t_m = df\n",
    "    cero_period = tiempo_entre_explosiones_min\n",
    "    t_inicio     = []\n",
    "    t_inicio_val = []\n",
    "    t_final      = []\n",
    "    t_final_val  = []\n",
    "    t_distancia  = []\n",
    "    t_cero = t[0]\n",
    "    t_last =int(t_cero)\n",
    "    \n",
    "    last_t = t[0]\n",
    "    very_last = t[0]\n",
    "    for ji in t[1:]:\n",
    "        if (ji - very_last) >= t_m*cero_period:\n",
    "            t_inicio.append([last_t])\n",
    "            t_inicio_val.append(y_array[int(last_t)])\n",
    "            t_final.append([very_last])\n",
    "            t_final_val.append(y_array[int(very_last)])\n",
    "            last_t = ji\n",
    "            if ji == t[-1]:\n",
    "                # hay que hacer un corte de emergencia\n",
    "                # los límites del intervalo de emergencia son', ji, ji\n",
    "                t_inicio.append([last_t])\n",
    "                t_inicio_val.append([y_array[int(last_t)]])\n",
    "                t_final.append([ji])\n",
    "                t_final_val.append(y_array[int(ji)])\n",
    "                break\n",
    "\n",
    "        if ji == t[-1]:\n",
    "            t_inicio.append([last_t])\n",
    "            t_inicio_val.append([y_array[int(last_t)]])\n",
    "            t_final.append([ji])\n",
    "            t_final_val.append(y_array[int(ji)])\n",
    "            break\n",
    "        very_last = ji\n",
    "   \n",
    "    tremores= False\n",
    "    for j in np.arange(len(t_final)):\n",
    "        t_distancia.append((t_final[j][0]-t_inicio[j][0])/t_m/60)\n",
    "        if (t_final[j][0]-t_inicio[j][0])/t_m/60 >1.5:\n",
    "            tremores = True\n",
    "\n",
    "\n",
    "    print(\"Distancias\",t_distancia)\n",
    "    print(\"inicio\",t_inicio)\n",
    "    print(\"final\",t_final)  \n",
    "    \n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.scatter(t_array,y_array,c='g')\n",
    "    plt.scatter(c_df.t,c_df.y, c='orange')\n",
    "    \n",
    "    # Agregar las barras verticales para indicar el inicio y fin del evento\n",
    "    for inicio, fin in zip(t_inicio, t_final):\n",
    "        plt.axvline(x=inicio, color='r', linestyle='--')\n",
    "        plt.axvline(x=fin, color='g', linestyle='--')\n",
    "\n",
    "    # Configurar las etiquetas de los ejes\n",
    "    plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "    plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=25)\n",
    "    plt.yticks(fontsize=25)\n",
    "    \n",
    "    # Mostrar el plot\n",
    "    plt.show()\n",
    "    \n",
    "    t_times = []\n",
    "    for i in range(len(t_inicio[1:])):\n",
    "        t_times.append(t_inicio[i])\n",
    "        t_times.append(t_final[i])\n",
    "\n",
    "    stream = st_EHZ\n",
    "    stream += st_HDF\n",
    "    templates = []\n",
    "    template_names = []\n",
    "    tr_times = []\n",
    "    tr_time_ini =[]\n",
    "    tr_time_fin =[]\n",
    "    explo_count = 0\n",
    "    explode = []\n",
    "    for v in tr_HDF.times(\"utcdatetime\")  :\n",
    "        tr_times.append(v)\n",
    "    \n",
    "    for i in range(len(t_inicio)):#[1:])):\n",
    "        tini = t_inicio[i][0]\n",
    "        tfin = t_final [i][0]\n",
    "        if tini < 0:\n",
    "            tini = 0\n",
    "        if tfin >= len(tr_times):\n",
    "            tfin = len(tr_times)-1\n",
    "        tr_time_ini.append(tr_times[int(tini)])\n",
    "        tr_time_fin.append(tr_times[int(tfin)])\n",
    "        explo_count +=1\n",
    "        explode.append([explo_count-1])\n",
    "     \n",
    "    tr_time_ini_2d = np.expand_dims(tr_time_ini, axis=1)\n",
    "    tr_time_fin_2d = np.expand_dims(tr_time_fin, axis=1)\n",
    "\n",
    "    the_times = np.concatenate((explode,tr_time_ini_2d,tr_time_fin_2d),axis=1)\n",
    "    HDF_times = pd.DataFrame(the_times, columns = ['explode','time_start','time_end'] )\n",
    "    \n",
    "    it = 0\n",
    "    \n",
    "    for ix in range(len(HDF_times)):\n",
    "        time_INI  = HDF_times.iloc[ix,1]    \n",
    "        time_FIN  = HDF_times.iloc[ix,2]\n",
    "        print (time_INI,time_FIN,time_FIN-time_INI)\n",
    "        \n",
    "    if tr_time_ini != [] and tr_time_fin !=[]:\n",
    "        for dti in tr_time_ini:\n",
    "            det_tr_inicio.append(dti)\n",
    "        for dtf in tr_time_fin:\n",
    "            det_tr_fin.append(dtf)\n",
    "\n",
    "\n",
    "det_tr_HDF_inicio = det_tr_inicio\n",
    "det_tr_HDF_fin = det_tr_fin            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a66d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eventos_sismo_acusticos=pd.concat([pd.Series(det_tr_EHZ_inicio),pd.Series(det_tr_EHZ_fin),pd.Series(det_tr_EHZ_fin)-pd.Series(det_tr_EHZ_inicio)], axis=1)\n",
    "df_eventos_sismo_acusticos.columns=['event_ini','event_fin','diff']\n",
    "df_eventos_sismo_acusticos.to_excel(\"df_eventos_sismo_acusticos.xlsx\")\n",
    "df_eventos_acusticos=pd.concat([pd.Series(det_tr_HDF_inicio),pd.Series(det_tr_HDF_fin),pd.Series(det_tr_HDF_fin)-pd.Series(det_tr_HDF_inicio)], axis=1)\n",
    "df_eventos_acusticos.columns=['event_ini','event_fin','diff']\n",
    "df_eventos_acusticos.to_excel(\"df_eventos_acusticos.xlsx\")\n",
    "df_eventos_sismicos=pd.concat([pd.Series(seismic_inicio),pd.Series(seismic_fin),pd.Series(seismic_fin)-pd.Series(seismic_inicio)], axis=1)\n",
    "df_eventos_sismicos.columns=['event_ini','event_fin','diff']\n",
    "df_eventos_sismicos.to_excel(\"df_eventos_sismicos.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fd4554",
   "metadata": {},
   "source": [
    "# Reacondicionamiento de intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_intervalos(inicio_intervalo, fin_intervalo):\n",
    "    n = len(inicio_intervalo)\n",
    "    i = 0\n",
    "    \n",
    "    while i < n - 1:\n",
    "        if ((inicio_intervalo[i + 1] - fin_intervalo[i]) < 1):\n",
    "            \n",
    "            # Si la diferencia es 1, entonces se deben unir los intervalos\n",
    "            fin_intervalo[i] = fin_intervalo[i + 1]\n",
    "            # Eliminamos el inicio y fin del intervalo siguiente\n",
    "            del inicio_intervalo[i + 1]\n",
    "            del fin_intervalo[i + 1]\n",
    "            n -= 1\n",
    "        else:\n",
    "            i += 1\n",
    "        \n",
    "    return inicio_intervalo, fin_intervalo\n",
    "\n",
    "seismic_inicio_ajustado, seismic_fin_ajustado = ajustar_intervalos(seismic_inicio, seismic_fin)\n",
    "det_tr_EHZ_inicio_ajustado, det_tr_EHZ_fin_ajustado = ajustar_intervalos(det_tr_EHZ_inicio, det_tr_EHZ_fin)\n",
    "det_tr_HDF_inicio_ajustado, det_tr_HDF_fin_ajustado = ajustar_intervalos(det_tr_HDF_inicio, det_tr_HDF_fin)\n",
    "\n",
    "print(len(det_tr_seismic_inicio),len(seismic_inicio_ajustado))\n",
    "print(len(det_tr_EHZ_inicio),len(det_tr_EHZ_inicio_ajustado))\n",
    "print(len(det_tr_HDF_inicio),len(det_tr_HDF_inicio_ajustado))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa48cae",
   "metadata": {},
   "source": [
    "# Preprocesamiento de detecciones de explosiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf_tiempos_ini = []\n",
    "ehz_tiempos_ini = []\n",
    "hdf_tiempos_fin = []\n",
    "ehz_tiempos_fin = []\n",
    "diff_hdf = []\n",
    "diff_ehz =[]\n",
    "diff_ini = []\n",
    "diff_fin =[]\n",
    "j = 0\n",
    "i = 0\n",
    "k =1\n",
    "\n",
    "el_tiempo_t = UTC(\"2022-09-17T01:41:26.380000Z\")\n",
    "el_tiempo_t2 = UTC(\"2022-09-17T01:41:26.460000Z\")\n",
    "lo_encontré= False\n",
    "while i < len(det_tr_HDF_inicio):\n",
    "    j=0\n",
    "    while j < len(det_tr_EHZ_inicio):\n",
    "        time_delta_seconds = abs(det_tr_HDF_inicio[i] - det_tr_EHZ_inicio[j]) #/ pd.Timedelta(seconds=1)\n",
    "\n",
    "        if (det_tr_HDF_inicio[i] <= det_tr_EHZ_inicio[i] \n",
    "            and det_tr_HDF_fin[i]>= det_tr_EHZ_fin[i]\n",
    "            and time_delta_seconds <=dif_ini_delay):\n",
    "            print('hallazgo:',k,'en i',i,' j:',j,'ehz:', det_tr_HDF_inicio[i], 'hdf: ',det_tr_EHZ_inicio[j], 'time_delta:', time_delta_seconds)\n",
    "            time_delta_seconds_fin = abs(det_tr_HDF_fin[i] - det_tr_EHZ_fin[j]) #/ pd.Timedelta(seconds=1)\n",
    "            print('  intervalo_HDF fin', det_tr_HDF_fin[i], 'inicio', det_tr_HDF_inicio[i], det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            print('  intervalo_EHZ fin', det_tr_EHZ_fin[j], 'inicio', det_tr_EHZ_inicio[j], det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j])\n",
    "            print('  intervalos EHZ',det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j],'HDF',det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            print('diferencia      ',  abs((det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j]) -(det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])))\n",
    "            hdf_tiempos_ini.append(det_tr_HDF_inicio[i])\n",
    "            ehz_tiempos_ini.append(det_tr_EHZ_inicio[j])\n",
    "            hdf_tiempos_fin.append(det_tr_HDF_fin[i])\n",
    "            ehz_tiempos_fin.append(det_tr_EHZ_fin[j])\n",
    "            diff_hdf.append(det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            diff_ehz.append(det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j])\n",
    "            diff_fin.append(((det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j]) -(det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])))\n",
    "            diff_ini.append((det_tr_EHZ_inicio[j]- det_tr_HDF_inicio[i]))\n",
    "            j+=1\n",
    "            k+=1\n",
    "            break\n",
    "        if (det_tr_EHZ_inicio[i] <= det_tr_HDF_inicio[i]\n",
    "            and det_tr_EHZ_fin[i]>= det_tr_HDF_fin[i]\n",
    "            and time_delta_seconds <=dif_ini_delay):\n",
    "            print('hallazgo:',k,'en i',i,' j:',j,'ehz:', det_tr_HDF_inicio[i], 'hdf: ',det_tr_EHZ_inicio[j], 'time_delta:', time_delta_seconds)\n",
    "            time_delta_seconds_fin = abs(det_tr_HDF_fin[i] - det_tr_EHZ_fin[j]) #/ pd.Timedelta(seconds=1)\n",
    "            print('  intervalo_HDF fin', det_tr_HDF_fin[i], 'inicio', det_tr_HDF_inicio[i], det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            print('  intervalo_EHZ fin', det_tr_EHZ_fin[j], 'inicio', det_tr_EHZ_inicio[j], det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j])\n",
    "            print('  intervalos EHZ',det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j],'HDF',det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            print('diferencia      ',  abs((det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j]) -(det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])))\n",
    "            hdf_tiempos_ini.append(det_tr_HDF_inicio[i])\n",
    "            ehz_tiempos_ini.append(det_tr_EHZ_inicio[j])\n",
    "            hdf_tiempos_fin.append(det_tr_HDF_fin[i])\n",
    "            ehz_tiempos_fin.append(det_tr_EHZ_fin[j])\n",
    "            diff_hdf.append(det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            diff_ehz.append(det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j])\n",
    "            diff_fin.append((det_tr_EHZ_fin[j]   - det_tr_HDF_fin[i]))\n",
    "            diff_ini.append((det_tr_EHZ_inicio[j]- det_tr_HDF_inicio[i]))\n",
    "            j+=1\n",
    "            k+=1\n",
    "            break    \n",
    "        if  (time_delta_seconds <=dif_ini_delay \n",
    "            ): \n",
    "            print('hallazgo:',k,'en i',i,' j:',j,'ehz:', det_tr_HDF_inicio[i], 'hdf: ',det_tr_EHZ_inicio[j], 'time_delta:', time_delta_seconds)\n",
    "            time_delta_seconds_fin = abs(det_tr_HDF_fin[i] - det_tr_EHZ_fin[j]) #/ pd.Timedelta(seconds=1)\n",
    "            print('  intervalo_HDF fin', det_tr_HDF_fin[i], 'inicio', det_tr_HDF_inicio[i], det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            print('  intervalo_EHZ fin', det_tr_EHZ_fin[j], 'inicio', det_tr_EHZ_inicio[j], det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j])\n",
    "            print('  intervalos EHZ',det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j],'HDF',det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            print('diferencia      ',  abs((det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j]) -(det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])))\n",
    "                         \n",
    "            hdf_tiempos_ini.append(det_tr_HDF_inicio[i])\n",
    "            ehz_tiempos_ini.append(det_tr_EHZ_inicio[j])\n",
    "            hdf_tiempos_fin.append(det_tr_HDF_fin[i])\n",
    "            ehz_tiempos_fin.append(det_tr_EHZ_fin[j])\n",
    "            diff_hdf.append(det_tr_HDF_fin[i] - det_tr_HDF_inicio[i])\n",
    "            diff_ehz.append(det_tr_EHZ_fin[j] - det_tr_EHZ_inicio[j])\n",
    "            diff_fin.append((det_tr_EHZ_fin[j]   - det_tr_HDF_fin[i]   ))\n",
    "            diff_ini.append((det_tr_EHZ_inicio[j]- det_tr_HDF_inicio[i]))\n",
    "            j+=1\n",
    "            k+=1\n",
    "            break\n",
    "        j+=1\n",
    "    i+=1\n",
    "df_intervalos = pd.concat([pd.Series(hdf_tiempos_ini), pd.Series(hdf_tiempos_fin), pd.Series(ehz_tiempos_ini), pd.Series(ehz_tiempos_fin), pd.Series(diff_hdf), pd.Series(diff_ehz), pd.Series(diff_ini), pd.Series(diff_fin)], axis=1)\n",
    "df_intervalos.columns =['hdf_ini','hdf_fin','ehz_ini','ehz_fin','diff_hdf','diff_ehz','diff_ini','diff_fin']\n",
    "df_intervalos.diff_fin.describe()\n",
    "df_intervalos.to_excel(\"df_intervalos.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d4004",
   "metadata": {},
   "source": [
    "# Cálculo de intervalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df_intervalos.hdf_ini.iloc[0] <= df_intervalos.ehz_ini.iloc[0]:\n",
    "    l_t_i = df_intervalos.hdf_ini.iloc[0]\n",
    "else:\n",
    "    l_t_i = df_intervalos.ehz_ini.iloc[0]\n",
    "j =0\n",
    "init()\n",
    "t_i = l_t_i+86400\n",
    "det_tr_ini =[]\n",
    "det_tr_fin = []\n",
    "l_t_i \n",
    "print(l_t_i,t_i)\n",
    "ini_hdf = df_intervalos['hdf_ini']\n",
    "num = 1\n",
    "while j <(len(df_intervalos)):\n",
    "    if (df_intervalos.hdf_ini.iloc[j] >= l_t_i and df_intervalos.hdf_ini.iloc[j] <= t_i and \n",
    "        df_intervalos.hdf_fin.iloc[j] >= l_t_i and df_intervalos.hdf_fin.iloc[j] <= t_i and\n",
    "        df_intervalos.ehz_ini.iloc[j] >= l_t_i and df_intervalos.ehz_ini.iloc[j] <= t_i and \n",
    "        df_intervalos.ehz_fin.iloc[j] >= l_t_i and df_intervalos.ehz_fin.iloc[j] <= t_i):\n",
    "            print('intervalo',num)\n",
    "            num +=1\n",
    "            print('hallazgo HDF',df_intervalos.hdf_ini.iloc[j])\n",
    "            print('hallazgo EHZ',df_intervalos.ehz_ini.iloc[j])\n",
    "            \n",
    "            if df_intervalos.diff_ini.iloc[j] >= 0:\n",
    "                print(\"--------------  se toma el tiempo HDF_ini\")\n",
    "                det_tr_ini.append(df_intervalos.hdf_ini.iloc[j])\n",
    "            elif df_intervalos.diff_ini.iloc[j] < 0:\n",
    "                print('--------------  se toma el tiempo EHZ_ini') \n",
    "                det_tr_ini.append(df_intervalos.ehz_ini.iloc[j])\n",
    "\n",
    "            if df_intervalos.diff_fin.iloc[j]   < 0: \n",
    "                print(\"                se toma el tiempo HDF fin\")   \n",
    "                det_tr_fin.append(df_intervalos.hdf_fin.iloc[j])\n",
    "            elif df_intervalos.diff_fin.iloc[j] >= 0:\n",
    "                print(\"                se toma el tiempo EHZ fin\")\n",
    "                det_tr_fin.append(df_intervalos.ehz_fin.iloc[j])                \n",
    "    j+=1\n",
    "\n",
    "df_eventos_filtrados = pd.concat([pd.Series(det_tr_ini), pd.Series(det_tr_fin),pd.Series(det_tr_fin)-pd.Series(det_tr_ini)], axis=1)\n",
    "df_eventos_filtrados.columns =['event_ini','event_fin','diff']\n",
    "df_eventos_filtrados.to_excel(\"df_eventos_filtrados.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdab364-18fe-45c9-b56e-58910a056331",
   "metadata": {},
   "source": [
    "# Calculo la correlación cruzada entre las ondas infrasónicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "st__HDF = read(\"GI.FG12.02.BDF.D.2022.260.mseed\")\n",
    "st__EHZ = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "st_HDF   = st__HDF.filter('bandpass', freqmin= fmin_HDF, freqmax=fmax_HDF, corners=2, zerophase=True)\n",
    "st_EHZ = st__EHZ.filter('bandpass', freqmin= fmin_EHZ, freqmax=fmax_EHZ, corners=2, zerophase=True)\n",
    "tr_HDF = st_HDF[0]\n",
    "tr_EHZ = st_EHZ[0]\n",
    "stream = st_HDF\n",
    "stream += st_EHZ\n",
    "detecciones_event_ini =[]\n",
    "detecciones_event_fin =[]\n",
    "detecciones_pascales_ehz = []\n",
    "detecciones_pascales_hdf = []\n",
    "detecciones_kurtosis = []\n",
    "detecciones_densidad = []\n",
    "detecciones_sesgo = []\n",
    "detecciones_diff_max = []\n",
    "detecciones_eventos_i =[]\n",
    "\n",
    "df_eventos_filtrados = pd.read_excel(\"df_eventos_filtrados.xlsx\")\n",
    "for i, eventos_row in df_eventos_filtrados.iterrows():\n",
    "    event__ini = UTC(eventos_row.event_ini)\n",
    "    event__fin = UTC(eventos_row.event_fin)\n",
    "    #pascal_multiplicador\n",
    "    if math.isnan(event__fin):\n",
    "        template_test = stream.slice(event__ini-15,event__ini+45)\n",
    "    else:    \n",
    "        template_test = stream.slice(event__ini,event__fin)\n",
    "    test_ehz = template_test[1]\n",
    "    test_hdf = template_test[0]\n",
    "    test_signal_ehz = test_ehz.data\n",
    "    test_signal_hdf = test_hdf.data\n",
    "    \n",
    "    # Calcula la correlación cruzada entre test_signal_ehz y test_signal_hdf\n",
    "    corr = signal.correlate(test_signal_ehz, test_signal_hdf, mode='same', method='fft')\n",
    "\n",
    "    # Normaliza la correlación cruzada\n",
    "    corr /= np.max(np.abs(corr))    \n",
    "    \n",
    "    # Encuentra el índice del máximo de la correlación cruzada\n",
    "    max_index = np.argmax(np.abs(corr))\n",
    "\n",
    "    # Calcula el desfase entre las dos señales\n",
    "    dt = max_index - len(test_signal_ehz) + 1\n",
    "    dt /= t_m  # t_m es la frecuencia de muestreo de las señales\n",
    "    \n",
    "    # Calcula la similitud entre las dos señales\n",
    "    similitud = np.max(np.abs(corr))\n",
    "    \n",
    "    # calcular la densidad de la distribución de la correlación cruzada\n",
    "    try:\n",
    "        density = gaussian_kde(corr)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # calcular la kurtosis de la distribución de la correlación cruzada\n",
    "    kurt = stats.kurtosis(corr)\n",
    "    skewness = stats.skew(corr)\n",
    "\n",
    "    # Calcular los percentiles\n",
    "    p25 = np.percentile(corr, 25)  # Percentil 25\n",
    "    p50 = np.percentile(corr, 50)  # Percentil 50 (mediana)\n",
    "    p75 = np.percentile(corr, 75)  # Percentil 75\n",
    "    \n",
    "    # Obtener el índice del valor máximo\n",
    "    idx_max_test_hdf = np.argmax(test_hdf)\n",
    "    idx_max_test_ehz = np.argmax(test_ehz)\n",
    "    idx_max_corr = np.argmax(corr)\n",
    "\n",
    "    print( i,\"ini\", eventos_row.event_ini,\"fin\", eventos_row.event_fin, \"kurt\",round(kurt,2),\"density\",round(density(-0.5)[0],3), \"sesgo\", round(skewness,3),\"diff\",abs(idx_max_test_hdf-idx_max_test_ehz)/t_m)\n",
    "    indices = np.where(np.array(corr) > cross_treshold)[0]\n",
    "    \n",
    "    if (len(indices) >0 and (kurt>3.6 or kurt <0) and density(-0.5) <0.135 and density(0.5) <0.2 ):       #2.74117647: #1.5:  valor dénsiti 0.135#similitud > 0.65 and np.abs(dt) < 0.06: \n",
    "        print(\"Pascales máximos EHZ\", np.max(test_signal_ehz)*pascal_multiplicador )\n",
    "        print(\"Pascales máximos HDF\", np.max(test_signal_hdf)*pascal_multiplicador )\n",
    "        print(\"Las señales son similares en el tiempo {:.2f} s\".format(max_index/t_m))\n",
    "        \n",
    "        detecciones_event_ini.append(eventos_row.event_ini)\n",
    "        detecciones_event_fin.append(eventos_row.event_fin)\n",
    "        detecciones_pascales_ehz.append(np.max(test_signal_ehz)*pascal_multiplicador)\n",
    "        detecciones_pascales_hdf.append(np.max(test_signal_hdf)*pascal_multiplicador)\n",
    "        detecciones_kurtosis.append(kurt)\n",
    "        detecciones_densidad.append(density(-0.5)[0])\n",
    "        detecciones_sesgo.append(skewness)\n",
    "        detecciones_eventos_i.append(i)\n",
    "        detecciones_diff_max.append(abs(idx_max_test_hdf-idx_max_test_ehz)/t_m)\n",
    "        \n",
    "        #template_test.plot()\n",
    "        test_hdf.plot()\n",
    "        test_ehz.plot()\n",
    "        plt.figure(figsize=(30,15))\n",
    "        plt.plot(test_hdf,c='orange', alpha=0.5, label='Onda acústica')\n",
    "        plt.plot(test_ehz, c='blue', alpha=0.5,  label='Onda sísmica')\n",
    "        plt.legend(fontsize=28)\n",
    "        plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "        plt.ylabel('Amplitud (cuentas digitales)', fontsize=30)\n",
    "\n",
    "        # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "        plt.xticks(fontsize=25)\n",
    "        plt.yticks(fontsize=25)\n",
    "        plt.show()\n",
    "        print(\"correlaciones\")\n",
    "        \n",
    "        plt.figure(figsize=(30,15))\n",
    "        plt.plot(corr)\n",
    "        plt.xlabel('Tiempo (50 puntos por segundo)', fontsize=30)\n",
    "        plt.ylabel('Coeficiente Correlación', fontsize=30)\n",
    "        plt.ylabel(\"Densidad\")\n",
    "        plt.legend(fontsize=28)\n",
    "\n",
    "        # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "        plt.xticks(fontsize=25)\n",
    "        plt.yticks(fontsize=25)\n",
    "        plt.show()\n",
    "        # graficar la distribución de la correlación cruzada\n",
    "        print(\"Kurtosis:\", kurt)\n",
    "        print(\"Densidad\", density(-0.5))\n",
    "        print(\"Sesgo\", skewness)\n",
    "        print(\"Similitud\", similitud, \"desfase \", np.abs(dt) )\n",
    "\n",
    "        # Obtener el índice del valor máximo\n",
    "        idx_max_test_hdf = np.argmax(test_hdf)\n",
    "        idx_max_test_ehz = np.argmax(test_ehz)\n",
    "        idx_max_corr = np.argmax(corr)\n",
    "\n",
    "        # Imprimir los resultados\n",
    "        print(\"Índice del valor máximo en test_hdf:\", idx_max_test_hdf)\n",
    "        print(\"Índice del valor máximo en test_ehz:\", idx_max_test_ehz)\n",
    "        print(\"Distancia entre maximos en segundos\", abs(idx_max_test_hdf-idx_max_test_ehz)/t_m)\n",
    "        \n",
    "        # Obtener índices de los valores mayores a 0.75\n",
    "        indices = np.where(np.array(corr) > 0.75)[0]\n",
    "\n",
    "        # Imprimir los resultados\n",
    "        print(\"Índices de los valores mayores a 0.75 en corr:\", indices)\n",
    "        sns.kdeplot(corr, shade=True)\n",
    "\n",
    "        # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.show()\n",
    "        \n",
    "df_detecciones_intervalos = pd.DataFrame({'evento':detecciones_eventos_i,'event_ini': detecciones_event_ini, 'event_fin': detecciones_event_fin, 'pascales_hdf': detecciones_pascales_hdf, 'pascales_ehz':detecciones_pascales_ehz, 'kurtosis':detecciones_kurtosis, 'sesgo':detecciones_sesgo, 'densidad':detecciones_densidad, 'diff_max':detecciones_diff_max})\n",
    "df_detecciones_intervalos.to_excel(\"de_detecciones_intervalos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eba5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eventos_row.event_ini, eventos_row.event_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_detecciones_intervalos)\n",
    "print(len(detecciones_event_ini),len(detecciones_event_fin))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ec45b",
   "metadata": {},
   "source": [
    "# Busco  la existencia de la onda sísmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44e911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_tiempos_ini = []\n",
    "event_tiempos_fin = []\n",
    "seismic_tiempos_ini = []\n",
    "seismic_tiempos_fin = []\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "k =1\n",
    "\n",
    "lo_encontré= False\n",
    "df_det = df_detecciones_intervalos\n",
    "df_sismicos = pd.read_excel(\"df_eventos_sismicos.xlsx\")\n",
    "\n",
    "# Convertir las columnas event_ini y event_fin a objetos UTCDateTime\n",
    "df_det['event_ini'] = df_det['event_ini'].apply(lambda x: UTC(x))\n",
    "df_det['event_fin'] = df_det['event_fin'].apply(lambda x: UTC(x))\n",
    "\n",
    "det_tr_seismic_inicio = df_sismicos['event_ini'] = df_sismicos['event_ini'].apply(lambda x: UTC(x))\n",
    "det_tr_seismic_fin    = df_sismicos['event_fin'] = df_sismicos['event_fin'].apply(lambda x: UTC(x))\n",
    "\n",
    "while i < len(df_det):\n",
    "\n",
    "    j=0\n",
    "    while j < len(det_tr_seismic_inicio):\n",
    "        time_delta_seconds = abs( df_det.event_ini[i] - det_tr_seismic_inicio[j]) #/ pd.Timedelta(seconds=1)\n",
    "        if  ((det_tr_seismic_inicio[j] -15<= df_det.event_ini[i] and\n",
    "              det_tr_seismic_fin[j]+100 >= df_det.event_fin[i]\n",
    "             )             \n",
    "            ) or (i == 310 and j in [888,890]):\n",
    "            print('hallazgo:',k,'en i',i,' j:',j,'ehz:', det_tr_seismic_inicio[j], 'hdf: ',df_det.event_ini[i], 'time_delta:', time_delta_seconds)\n",
    "            time_delta_seconds_fin = abs(df_det.event_fin[i] - df_det.event_fin[i]) #/ pd.Timedelta(seconds=1)\n",
    "            print('  intervalo_evento   ', df_det.event_fin[i], 'inicio', df_det.event_ini[i], df_det.event_fin[i] - df_det.event_ini[i])\n",
    "            print('  intervalos seismic ',det_tr_seismic_fin[j],'inicio', det_tr_seismic_inicio[j],det_tr_seismic_fin[j] - det_tr_seismic_inicio[j])\n",
    "\n",
    "            event_tiempos_ini.append(df_det.event_ini[i])\n",
    "            event_tiempos_fin.append(df_det.event_fin[i])\n",
    "            seismic_tiempos_ini.append(det_tr_seismic_inicio[j])\n",
    "            seismic_tiempos_fin.append(det_tr_seismic_fin[j])\n",
    "            \n",
    "            j+=1\n",
    "            k+=1\n",
    "            break    \n",
    "        j+=1\n",
    "    i+=1\n",
    "df_intervalos_2 = pd.concat([pd.Series(event_tiempos_ini), pd.Series(event_tiempos_fin),pd.Series(seismic_tiempos_ini),pd.Series(seismic_tiempos_fin)], axis=1)\n",
    "df_intervalos_2.columns =['event_ini','event_fin','seismic_ini','seismic_fin']\n",
    "df_intervalos_2['grand_coupling'] = df_intervalos_2['event_ini'] - df_intervalos_2['seismic_ini']\n",
    "\n",
    "df_intervalos_2.to_excel(\"df_intervalos_2.xlsx\")\n",
    "print(df_intervalos_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb9d429-ee6e-4e0d-9bfb-af3b82ec1b0c",
   "metadata": {},
   "source": [
    "# Calculo las correlaciones cruzadas con la onda sísmica pura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "st__HDF = read(\"GI.FG12.02.BDF.D.2022.260.mseed\")\n",
    "st__EHZ = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "st__SMC = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "\n",
    "st_HDF   = st__HDF.filter('bandpass', freqmin= fmin_HDF, freqmax=fmax_HDF, corners=2, zerophase=True)\n",
    "st_EHZ = st__EHZ.filter('bandpass', freqmin= fmin_EHZ, freqmax=fmax_EHZ, corners=2, zerophase=True)\n",
    "st_smc = st__SMC.filter('highpass', freq= fmin_seismic,                       corners=8, zerophase=True)\n",
    "    \n",
    "fmin_HDF=0.5\n",
    "fmax_HDF=20\n",
    "fmin_EHZ = 5#0.5 #5 #.5\n",
    "fmax_EHZ = 15#5   #15 #7\n",
    "fmin_seismic = 0.2\n",
    "fmax_seismic = 7\n",
    "\n",
    "\n",
    "tr_HDF = st_HDF[0]\n",
    "tr_EHZ = st_EHZ[0]\n",
    "stream = st_HDF\n",
    "stream += st_EHZ\n",
    "df_intervalos_2 = pd.read_excel(\"df_intervalos_2.xlsx\")\n",
    "conteo_explosiones_volcanicas = 0\n",
    "indice_explosiones_volcanicas = []\n",
    "grand_coupling_actualizado = []\n",
    "for i, eventos_row in df_intervalos_2.iterrows():\n",
    "    event__ini = UTC(eventos_row.event_ini)\n",
    "    event__fin = UTC(eventos_row.event_fin)\n",
    "    seismic__ini = UTC(eventos_row.seismic_ini)\n",
    "    seismic__fin = UTC(eventos_row.seismic_fin)\n",
    "\n",
    "    if math.isnan(event__fin):\n",
    "        template_test = stream.slice(event__ini-15, event__ini+45)\n",
    "    else:    \n",
    "        template_test = stream.slice(event__ini, event__fin)\n",
    "        seismic_test = st_smc.slice(seismic__ini, seismic__fin)\n",
    "    \n",
    "    test_ehz = template_test[1]\n",
    "    test_hdf = template_test[0]\n",
    "    test_smc = seismic_test[0]\n",
    "    test_signal_ehz = test_ehz.data\n",
    "    test_signal_hdf = test_hdf.data   \n",
    "    \n",
    "    print(\"   \")\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    print(i)\n",
    "    print(eventos_row)\n",
    "    \n",
    "    tstmp_ehz = []\n",
    "    tstmp_hdf = []\n",
    "    tstmp_smc = []\n",
    "    \n",
    "##############################\n",
    "    for v in test_ehz.times(\"timestamp\")  :\n",
    "        tstmp_ehz.append([v])\n",
    "    for v in test_hdf.times(\"timestamp\")  :\n",
    "        tstmp_hdf.append([v])\n",
    "    for v in test_smc.times(\"timestamp\")  :\n",
    "        tstmp_smc.append([v])\n",
    "##############################\n",
    "\n",
    "    # Obtener datos relevantes de cada fila de eventos_row\n",
    "    test_ehz_data = test_ehz.data\n",
    "    test_hdf_data = test_hdf.data\n",
    "    test_smc_data = test_smc.data\n",
    "    \n",
    "    # Calcula la correlación cruzada entre test_ehz.data y test_smc.data\n",
    "    corr_ehz_hdf = signal.correlate(test_ehz_data, test_hdf_data, mode='same', method='fft')\n",
    "\n",
    "    # Calcula la correlación cruzada entre test_ehz.data y test_smc.data\n",
    "    corr_ehz_smc = signal.correlate(test_ehz_data, test_smc_data, mode='same', method='fft')\n",
    "\n",
    "    # Calcula la correlación cruzada entre test_hdf.data y test_smc.data\n",
    "    corr_hdf_smc = signal.correlate(test_hdf_data, test_smc_data, mode='same', method='fft')\n",
    "\n",
    "    # Calcula la correlación cruzada entre corr_ehz_smc y corr_hdf_smc\n",
    "    corr_corr_ehz_smc_hdf_smc = signal.correlate(corr_ehz_smc, corr_hdf_smc, mode='same', method='fft')\n",
    "\n",
    "    # Normaliza las correlaciones cruzadas\n",
    "    corr_ehz_smc /= np.max(np.abs(corr_ehz_smc))\n",
    "    corr_hdf_smc /= np.max(np.abs(corr_hdf_smc))\n",
    "    corr_corr_ehz_smc_hdf_smc /= np.max(np.abs(corr_corr_ehz_smc_hdf_smc))\n",
    "\n",
    "     # Calcular la densidad de la distribución de la correlación cruzada (EHZ - SMC)\n",
    "    density_ehz_hdf = gaussian_kde(corr_ehz_hdf)\n",
    "\n",
    "    # Calcular la densidad de la distribución de la correlación cruzada (EHZ - SMC)\n",
    "    density_ehz_smc = gaussian_kde(corr_ehz_smc)\n",
    "\n",
    "    # Calcular la densidad de la distribución de la correlación cruzada (HDF - SMC)\n",
    "    density_hdf_smc = gaussian_kde(corr_hdf_smc)\n",
    "\n",
    "    # Calcular la densidad de la distribución de la correlación cruzada (corr_ehz_smc - corr_hdf_smc)\n",
    "    density_corr_ehz_smc_hdf_smc = gaussian_kde(corr_corr_ehz_smc_hdf_smc)\n",
    "\n",
    "    # Calcular la kurtosis de la distribución de la correlación cruzada (EHZ - SMC)\n",
    "    kurt_ehz_smc = kurtosis(corr_ehz_smc)\n",
    "\n",
    "    # Calcular la kurtosis de la distribución de la correlación cruzada (HDF - SMC)\n",
    "    kurt_hdf_smc = kurtosis(corr_hdf_smc)\n",
    "\n",
    "    # Calcular la kurtosis de la distribución de la correlación cruzada (corr_ehz_smc - corr_hdf_smc)\n",
    "    kurt_corr_ehz_smc_hdf_smc = kurtosis(corr_corr_ehz_smc_hdf_smc)\n",
    "\n",
    "    # Calcular la asimetría (skewness) de la distribución de la correlación cruzada (EHZ - SMC)\n",
    "    skewness_ehz_smc = skew(corr_ehz_smc)\n",
    "\n",
    "    # Calcular la asimetría (skewness) de la distribución de la correlación cruzada (HDF - SMC)\n",
    "    skewness_hdf_smc = skew(corr_hdf_smc)\n",
    "\n",
    "    # Calcular la asimetría (skewness) de la distribución de la correlación cruzada (corr_ehz_smc - corr_hdf_smc)\n",
    "    skewness_corr_ehz_smc_hdf_smc = skew(corr_corr_ehz_smc_hdf_smc)\n",
    "\n",
    "    # Obtener el índice del valor máximo en las señales originales\n",
    "    idx_max_test_ehz = np.argmax(test_ehz_data)\n",
    "    idx_max_test_smc = np.argmax(test_smc_data)\n",
    "    idx_max_test_hdf = np.argmax(test_hdf_data)\n",
    "\n",
    "    # Obtener el índice del valor máximo en la correlación cruzada (EHZ - SMC)\n",
    "    idx_max_corr_ehz_smc = np.argmax(corr_ehz_smc)\n",
    "\n",
    "    # Obtener el índice del valor máximo en la correlación cruzada (HDF - SMC)\n",
    "    idx_max_corr_hdf_smc = np.argmax(corr_hdf_smc)\n",
    "\n",
    "    # Obtener el índice del valor máximo en la correlación cruzada (corr_ehz_smc - corr_hdf_smc)\n",
    "    idx_max_corr_corr_ehz_smc_hdf_smc = np.argmax(corr_corr_ehz_smc_hdf_smc)\n",
    "\n",
    "\n",
    "    grand_coupling_actualizado.append(((idx_max_test_ehz-idx_max_test_smc)/t_m)+((idx_max_test_hdf-idx_max_test_smc)/t_m)/2)\n",
    "    g_coup_crestas = (((idx_max_test_ehz-idx_max_test_smc)/t_m)+((idx_max_test_hdf-idx_max_test_smc)/t_m)/2)\n",
    "    print (\"----------------------------------  grand coupling -----------: \",event__ini-seismic__ini)\n",
    "    print (\"----------------------------------  grand coupling crestas----: \",(((idx_max_test_ehz-idx_max_test_smc)/t_m)+((idx_max_test_hdf-idx_max_test_smc)/t_m)/2))\n",
    "    \n",
    "    if  ((event__ini-seismic__ini >=0 ) or (g_coup_crestas >0 ) )and ((((kurt_corr_ehz_smc_hdf_smc>1.5) and # or kurt_corr_ehz_smc_hdf_smc <0) and\n",
    "          (kurt_hdf_smc>2) and              \n",
    "          (kurt_ehz_smc>2) \n",
    "         ) or\n",
    "        ((kurt_corr_ehz_smc_hdf_smc>1.1) and \n",
    "          (kurt_hdf_smc>1.5) and             \n",
    "          (kurt_ehz_smc>5) \n",
    "         ) or\n",
    "        ((kurt_corr_ehz_smc_hdf_smc>1.1) and \n",
    "          (kurt_hdf_smc>5) and              \n",
    "          (kurt_ehz_smc>1.5) \n",
    "         ) or\n",
    "        ((kurt_corr_ehz_smc_hdf_smc>1.4) and \n",
    "          (kurt_hdf_smc>5) and              \n",
    "          (kurt_ehz_smc>1.1) \n",
    "         )or\n",
    "        ((kurt_corr_ehz_smc_hdf_smc>1.4) and \n",
    "          (kurt_hdf_smc>5) and              \n",
    "          (kurt_ehz_smc>1.1) \n",
    "         ) or\n",
    "         (kurt_corr_ehz_smc_hdf_smc>1.6)\n",
    "        )and              \n",
    "         density_corr_ehz_smc_hdf_smc(-0.5) <0.25 and density_corr_ehz_smc_hdf_smc(0.5) <0.25): \n",
    "        \n",
    "    # Imprimir los resultados de los cálculos\n",
    "        conteo_explosiones_volcanicas +=1\n",
    "        indice_explosiones_volcanicas.append(i)\n",
    "        print(\"Kurtosis de la correlación cruzada (EHZ - SMC): \", kurt_ehz_smc)\n",
    "        print(\"Kurtosis de la correlación cruzada (HDF - SMC): \", kurt_hdf_smc)\n",
    "        print(\"Kurtosis de la correlación cruzada (EHZ-SMC - HDF-SMC): \", kurt_corr_ehz_smc_hdf_smc)\n",
    "        print(\"Asimetría de la correlación cruzada (EHZ - SMC): \", skewness_ehz_smc)\n",
    "        print(\"Asimetría de la correlación cruzada (HDF - SMC): \", skewness_hdf_smc)\n",
    "        print(\"Asimetría de la correlación cruzada (EHZ-SMC - HDF-SMC): \", skewness_corr_ehz_smc_hdf_smc)\n",
    "        print(\"Densidad de la correlacion cruzada (EHZ - SMC): \",density_ehz_smc(0.5))\n",
    "        print(\"Densidad de la correlacion cruzada (HDF - SMC): \",density_hdf_smc(0.5))\n",
    "        print(\"Densidad de la correlacion cruzada (EHZ-SMC - HDF-SMC): \",density_corr_ehz_smc_hdf_smc(0.5))\n",
    "\n",
    "        print(\"Índice del máximo en EHZ: \", idx_max_test_ehz)\n",
    "        print(\"Índice del máximo en SMC: \", idx_max_test_smc)\n",
    "        print(\"Índice del máximo en HDF: \", idx_max_test_hdf)\n",
    "        print(\"Grandcoupling EHZ-SMC -segundos-:\", (idx_max_test_ehz-idx_max_test_smc)/t_m)\n",
    "        print(\"Grandcoupling HDF-SMC -segundos-:\", (idx_max_test_hdf-idx_max_test_smc)/t_m)\n",
    "        print(\"Índice del máximo en la correlación cruzada (EHZ - SMC): \", idx_max_corr_ehz_smc)\n",
    "        print(\"Índice del máximo en la correlación cruzada (HDF - SMC): \", idx_max_corr_hdf_smc)\n",
    "        print(\"Índice del máximo en la correlación cruzada (EHZ-SMC - HDF-SMC): \", idx_max_corr_corr_ehz_smc_hdf_smc)\n",
    "\n",
    "        # muestro el plot de las tres señales    \n",
    "        test_ehz.plot()\n",
    "        test_hdf.plot()\n",
    "        test_smc.plot()\n",
    "\n",
    "        plt.plot(np.linspace(min(corr_ehz_hdf), max(corr_ehz_hdf), 100), density_ehz_hdf(np.linspace(min(corr_ehz_hdf), max(corr_ehz_hdf), 100)), label='Densidad (IST - ISA)', color='green')\n",
    "        plt.xlabel('Valor de correlación', fontsize=14)\n",
    "        plt.ylabel('Densidad', fontsize=14)\n",
    "        plt.title('Densidad de la correlación cruzada (IST - ISA)', fontsize=14)\n",
    "        plt.legend(fontsize=14)\n",
    "\n",
    "        # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "        plt.xticks(fontsize=15)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # Crear una figura para trazar las correlaciones cruzadas y las densidades\n",
    "        fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(25, 45))\n",
    "\n",
    "    # Trazar la correlación cruzada entre test_ehz.data y test_smc.data\n",
    "        \n",
    "        # Ajustar los márgenes entre los subplots\n",
    "        plt.subplots_adjust(hspace=1)  # Puedes ajustar el valor 0.4 según tus necesidades\n",
    "        ax1.plot(corr_ehz_smc, label='Correlación cruzada (IST - SMP)', color='green')\n",
    "        ax1.set_xlabel('Desplazamiento', fontsize=30)\n",
    "        ax1.set_ylabel('Valor de correlación', fontsize=30)\n",
    "        ax1.set_title('Correlación cruzada normalizada entre IST y SMP', fontsize=25)\n",
    "        ax1.legend(fontsize=25)\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=25)\n",
    "\n",
    "    # Trazar la correlación cruzada entre test_hdf.data y test_smc.data\n",
    "        ax2.plot(corr_hdf_smc, label='Correlación cruzada (ISA - SMP)', color='blue')\n",
    "        ax2.set_xlabel('Desplazamiento', fontsize=30)\n",
    "        ax2.set_ylabel('Valor de correlación', fontsize=30)\n",
    "        ax2.set_title('Correlación cruzada normalizada entre ISA y SMP', fontsize=25)\n",
    "        ax2.legend(fontsize=25)\n",
    "        ax2.tick_params(axis='both', which='major', labelsize=25)\n",
    "\n",
    "    # Trazar la correlación cruzada entre corr_ehz_smc y corr_hdf_smc\n",
    "        ax3.plot(corr_corr_ehz_smc_hdf_smc, label='Correlación cruzada (IST-SMP - ISA-SMP)', color='purple')\n",
    "        ax3.set_xlabel('Desplazamiento', fontsize=30)\n",
    "        ax3.set_ylabel('Valor de correlación', fontsize=30)\n",
    "        ax3.set_title('Correlación cruzada normalizada entre (IST-SMP) e (ISA-SMP)', fontsize=25)\n",
    "        ax3.legend(fontsize=25)\n",
    "        ax3.tick_params(axis='both', which='major', labelsize=25)\n",
    "\n",
    "    # Trazar la densidad de la correlación cruzada (EHZ - SMC)\n",
    "        x1 = np.linspace(min(corr_ehz_smc), max(corr_ehz_smc), 100)\n",
    "        ax4.plot(x1, density_ehz_smc(x1), label='Densidad (IST - SMP)', color='green')\n",
    "        ax4.set_xlabel('Valor de correlación', fontsize=30)\n",
    "        ax4.set_ylabel('Densidad', fontsize=30)\n",
    "        ax4.set_title('Densidad de la correlación cruzada (IST - SMP)', fontsize=25)\n",
    "        ax4.legend(fontsize=25)\n",
    "        ax4.tick_params(axis='both', which='major', labelsize=25)\n",
    "\n",
    "    # Trazar la densidad de la correlación cruzada (HDF - SMC)\n",
    "        x2 = np.linspace(min(corr_hdf_smc), max(corr_hdf_smc), 100)\n",
    "        ax5.plot(x2, density_hdf_smc(x2), label='Densidad (ISA - SMP)', color='blue')\n",
    "        ax5.set_xlabel('Valor de correlación', fontsize=30)\n",
    "        ax5.set_ylabel('Densidad', fontsize=30)\n",
    "        ax5.set_title('Densidad de la correlación cruzada (ISA - SMP)', fontsize=25)\n",
    "        ax5.legend(fontsize=25)\n",
    "        ax5.tick_params(axis='both', which='major', labelsize=25)\n",
    "\n",
    "    # Trazar la densidad de la correlación cruzada (EHZ-SMC - HDF-SMC)\n",
    "        x3 = np.linspace(min(corr_corr_ehz_smc_hdf_smc), max(corr_corr_ehz_smc_hdf_smc), 100)\n",
    "        ax6.plot(x3, density_corr_ehz_smc_hdf_smc(x3), label='Densidad (IST-SMP - ISA-SMP)', color='purple')\n",
    "        ax6.set_xlabel('Valor de correlación', fontsize=30)\n",
    "        ax6.set_ylabel('Densidad', fontsize=30)\n",
    "        ax6.set_title('Densidad de la correlación cruzada (IST-SMP - ISA-SMP)', fontsize=25)\n",
    "        ax6.legend(fontsize=25)\n",
    "        ax6.tick_params(axis='both', which='major', labelsize=25)\n",
    "\n",
    "        # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "        plt.xticks(fontsize=25)\n",
    "        plt.yticks(fontsize=25)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "        # Crear una figura\n",
    "        fig, (ax_hdf, ax_ehz, ax_seismic) = plt.subplots(3, 1, sharex=True, figsize=(25, 45))\n",
    "        ax_hdf.plot(tstmp_hdf,test_hdf.data, c='orange', alpha=0.5)\n",
    "        ax_hdf.set_title('Onda acústica', fontsize=30)\n",
    "        ax_ehz.plot(tstmp_ehz,test_ehz.data, c='blue', alpha=0.5)\n",
    "        ax_ehz.set_title('Onda sismo-acústica', fontsize=30)\n",
    "        ax_seismic.plot(tstmp_smc,test_smc.data, c='green', alpha=0.5)\n",
    "        ax_seismic.set_title('Onda sísmica', fontsize=30)\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "        plt.xticks(fontsize=25)\n",
    "        plt.yticks(fontsize=25)\n",
    "        plt.show()\n",
    "\n",
    "#------------\n",
    "        fig, ax1 = plt.subplots(figsize=(30, 15))\n",
    "\n",
    "    # Trazar tstmp_ehz y test_ehz.data en el primer eje\n",
    "        ax1.plot(tstmp_ehz, test_ehz.data, c='orange', alpha=1, label='Onda acústica detectada por sismómetro')\n",
    "        ax1.set_xlabel('Tiempo (50 puntos por segundo)', fontsize=35)\n",
    "        ax1.set_ylabel('Amplitud (cuentas digitales) - Acústica-Sismica', fontsize=35, color='black')\n",
    "        ax1.tick_params(axis='y', labelcolor='black')\n",
    "        ax1.legend(fontsize=35, loc='upper left')\n",
    "        ax1.tick_params(axis='y', labelcolor='black', labelsize=35)\n",
    "        ax1.tick_params(axis='x', labelsize=35)\n",
    "        ax1.legend(fontsize=35, loc='upper left')\n",
    "\n",
    "    # Crear un segundo eje compartiendo el mismo eje x\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "    # Trazar tstmp_hdf y test_hdf.data en el segundo eje\n",
    "        ax2.plot(tstmp_hdf, test_hdf.data, c='blue', alpha=0.7, label='Onda acústica detectada por microbarómetro')\n",
    "        ax2.set_ylabel('Amplitud (cuentas digitales) - Acústica-Atmosférica', fontsize=35, color='blue')\n",
    "        ax2.tick_params(axis='y', labelcolor='black')\n",
    "        ax2.legend(fontsize=35, loc='upper right')\n",
    "        ax2.tick_params(axis='y', labelcolor='blue', labelsize=35)\n",
    "        ax2.legend(fontsize=35, loc='upper right')\n",
    "        \n",
    "    # Crear un tercer eje compartiendo el mismo eje x\n",
    "        ax3 = ax1.twinx()\n",
    "        \n",
    "    # Trazar tstmp_smc y test_smc.data en el tercer eje\n",
    "        ax3.plot(tstmp_smc, test_smc.data, c='green', alpha=0.5, label='Onda sísmica')\n",
    "        ax3.set_ylabel('Amplitud (cuentas digitales) - Sísmica', fontsize=35, color='black')\n",
    "        ax3.tick_params(axis='y', labelcolor='black')\n",
    "        ax3.legend(fontsize=35, loc='lower right')\n",
    "\n",
    "        # Desplazar el tercer eje a la derecha\n",
    "        ax3.spines['right'].set_position(('outward', 160))  # Ajusta el valor según necesites\n",
    "        \n",
    "    # Agregar líneas horizontales en cero a cada eje\n",
    "        ax1.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "        ax2.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "        ax3.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "        \n",
    "        \n",
    "        # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "        plt.xticks(fontsize=25)\n",
    "        plt.yticks(fontsize=25)\n",
    "        plt.show()        \n",
    "        \n",
    "    else:\n",
    "        print(\"Kurtosis de la correlación cruzada (EHZ - SMC): \", kurt_ehz_smc)\n",
    "        print(\"Kurtosis de la correlación cruzada (HDF - SMC): \", kurt_hdf_smc)\n",
    "        print(\"Kurtosis de la correlación cruzada (EHZ-SMC - HDF-SMC): \", kurt_corr_ehz_smc_hdf_smc)\n",
    "        print(\"Densidad de la correlacion cruzada (EHZ-SMC - HDF-SMC): (-0.5) \",density_corr_ehz_smc_hdf_smc(-0.5))\n",
    "        print(\"Densidad de la correlacion cruzada (EHZ-SMC - HDF-SMC): (.5) \",density_corr_ehz_smc_hdf_smc(0.5))\n",
    "        indice_explosiones_volcanicas.append(\"\")\n",
    "print(\"\")\n",
    "\n",
    "print (\"Cantidad de explosiones volcánicas detectadas:\", conteo_explosiones_volcanicas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1534bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_intervalos_2['explosion_volcanica'] = indice_explosiones_volcanicas\n",
    "df_intervalos_2['grand_coupling_crestas'] = grand_coupling_actualizado\n",
    "df_intervalos_2.to_excel(\"df_intervalos_2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22c423-501b-4318-8731-9c2e34427558",
   "metadata": {},
   "source": [
    "# Tomo recortes del catálogo base del Insivumeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ecacaa-d5f3-4720-8b44-85a07e12a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "archivo_excel = \"Catálogo_Explosiones_Fuego_17092022.xlsx\"\n",
    "\n",
    "# Leer el archivo Excel\n",
    "data = pd.read_excel(archivo_excel, header=None, names=['fecha', 'No. de serie', 'estado'])\n",
    "\n",
    "# Descartar la segunda columna\n",
    "data.drop(columns=['No. de serie'], inplace=True)\n",
    "\n",
    "# Crear una lista vacía para almacenar las marcas de tiempo\n",
    "marcas_de_tiempo = []\n",
    "\n",
    "var_Ex  = pd.NaT\n",
    "var_ExG = pd.NaT\n",
    "var_NS  = pd.NaT\n",
    "\n",
    "# Iterar sobre los datos originales\n",
    "for index, row in data.iterrows():\n",
    "    if row.estado == \"Ex\":\n",
    "        var_Ex = UTC(row.fecha)\n",
    "    if row.estado == \"ExG\":\n",
    "        var_ExG = UTC(row.fecha)\n",
    "    if row.estado == \"NS\":\n",
    "        var_NS = UTC(row.fecha)\n",
    "        # Agregar registros vacíos a la lista de marcas de tiempo\n",
    "        marcas_de_tiempo.append({'Ex': var_Ex, 'ExG': var_ExG, 'NS': var_NS})\n",
    "        var_Ex  = pd.NaT\n",
    "        var_ExG = pd.NaT\n",
    "        var_NS  = pd.NaT\n",
    "\n",
    "# Imprimir la lista resultante\n",
    "for evento in marcas_de_tiempo:\n",
    "    print(evento)\n",
    "    \n",
    "# Convertir la lista de marcas de tiempo en un DataFrame\n",
    "df_EV_BASE = pd.DataFrame(marcas_de_tiempo)\n",
    "\n",
    "print(df_EV_BASE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a640e-016a-4547-b92c-d93a3182296b",
   "metadata": {},
   "source": [
    "# Guardo archivos mseed de los recortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13937e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "st__HDF = read(\"GI.FG12.02.BDF.D.2022.260.mseed\")\n",
    "st__EHZ = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "st__SMC = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "\n",
    "fmin_HDF=0.5\n",
    "fmax_HDF=20\n",
    "fmin_EHZ = 5\n",
    "fmax_EHZ = 15\n",
    "fmin_seismic = 0.2\n",
    "fmax_seismic = 7\n",
    "\n",
    "st_HDF   = st__HDF.filter('bandpass', freqmin= fmin_HDF, freqmax=fmax_HDF, corners=2, zerophase=True)\n",
    "st_EHZ = st__EHZ.filter('bandpass', freqmin= fmin_EHZ, freqmax=fmax_EHZ, corners=2, zerophase=True)\n",
    "st_smc = st__SMC.filter('highpass', freq= fmin_seismic,                       corners=8, zerophase=True)\n",
    "st_smc = st_smc\n",
    "tr_HDF = st_HDF[0]\n",
    "tr_EHZ = st_EHZ[0]\n",
    "\n",
    "# Define una lista de colores para las trazas\n",
    "colors = [\"red\", \"blue\"]\n",
    "for i, eventos_row in df_EV_BASE.iterrows():\n",
    "    print(eventos_row)\n",
    "    AAW_test = st_HDF.slice(eventos_row.Ex, eventos_row.NS)\n",
    "    GAW_test = st_EHZ.slice(eventos_row.Ex, eventos_row.NS)\n",
    "    seismic_test = st_smc.slice(eventos_row.Ex, eventos_row.NS)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    AAW_test.plot(color = \"red\")\n",
    "    GAW_test.plot(color = \"blue\")\n",
    "    seismic_test.plot(color=\"green\")\n",
    "    \n",
    "    template_dir = \"slices\"\n",
    "    if not os.path.exists(template_dir):\n",
    "        os.makedirs(template_dir)\n",
    "    AAW_test.write(os.path.join(template_dir, f\"{eventos_row.name}_AAW.mseed\"), format=\"MSEED\")\n",
    "    GAW_test.write(os.path.join(template_dir, f\"{eventos_row.name}_GAW.name.mseed\"), format=\"MSEED\")\n",
    "    seismic_test.write(os.path.join(template_dir, f\"{eventos_row.name}_seismic.mseed\"), format=\"MSEED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba41c2d-d8f5-456c-8152-5e14d4f4c2b4",
   "metadata": {},
   "source": [
    "# Se muestran los espectros de las explociones del catalogo del Insivumeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c6be3-b7e5-4771-a364-c55cb59afd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from obspy import read\n",
    "\n",
    "# Directorio donde se encuentran los archivos MSEED\n",
    "directory = \"slices\"\n",
    "\n",
    "# Verifica si el directorio existe\n",
    "if not os.path.exists(directory):\n",
    "    print(f\"El directorio '{directory}' no existe.\")\n",
    "    exit()\n",
    "\n",
    "# Obtén la lista de archivos MSEED en el directorio\n",
    "mseed_files = [file for file in os.listdir(directory) if file.endswith(\".mseed\")]\n",
    "print(mseed_files)\n",
    "# Itera sobre cada archivo MSEED\n",
    "for file in mseed_files:\n",
    "    # Lee el archivo MSEED\n",
    "    st = read(os.path.join(directory, file))\n",
    "    \n",
    "    # Verifica si el archivo es sísmico o acústico\n",
    "    if \"seismic\" in file:\n",
    "        # Realiza las operaciones necesarias con el evento sísmico\n",
    "        print(f\"Evento sísmico: {file}\")\n",
    "        for trace in st:\n",
    "            print(trace)\n",
    "            trace.plot()\n",
    "            \n",
    "            # Realiza la transformada de Fourier\n",
    "            spectrum_seismic = np.fft.fft(trace.data)\n",
    "        \n",
    "            # Calcula las frecuencias correspondientes\n",
    "            freq_seismic = np.fft.fftfreq(len(trace.data), d=1/trace.stats.sampling_rate)\n",
    "        \n",
    "            # Grafica el espectro\n",
    "            plt.figure()\n",
    "            plt.plot(np.abs(freq_seismic), np.abs(spectrum_seismic))\n",
    "            plt.xlabel('Frecuencia (Hz)', fontsize=15)\n",
    "            plt.ylabel('Amplitud', fontsize=15)\n",
    "            plt.title('Espectro de onda sismica ' + trace.stats.station + ' - ' + trace.stats.channel,fontsize=12)\n",
    "            plt.grid(True)\n",
    "            \n",
    "            # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "            plt.xticks(fontsize=15)\n",
    "            plt.yticks(fontsize=15)\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "    if \"AAW\" in file:\n",
    "        # Realiza las operaciones necesarias con el evento sísmico\n",
    "        print(f\"Evento acústico atmosférico: {file}\")\n",
    "        for trace in st:\n",
    "            print(trace)\n",
    "            trace.plot()\n",
    "\n",
    "            # Realiza la transformada de Fourier\n",
    "            spectrum_AAW = np.fft.fft(trace.data)\n",
    "        \n",
    "            # Calcula las frecuencias correspondientes\n",
    "            freq_AAW = np.fft.fftfreq(len(trace.data), d=1/trace.stats.sampling_rate)\n",
    "        \n",
    "            # Grafica el espectro\n",
    "            plt.figure()\n",
    "            plt.plot(np.abs(freq_AAW), np.abs(spectrum_AAW))\n",
    "            plt.xlabel('Frecuencia (Hz)')\n",
    "            plt.ylabel('Amplitud')\n",
    "            plt.title('Espectro de onda acústica atmosférica ' + trace.stats.station + ' - ' + trace.stats.channel,fontsize=12)\n",
    "            plt.grid(True)\n",
    "            # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "            plt.xticks(fontsize=15)\n",
    "            plt.yticks(fontsize=15)\n",
    "            plt.show()\n",
    "                        \n",
    "    else:\n",
    "        # Realiza las operaciones necesarias con los eventos acústicos\n",
    "        print(f\"Evento acústico terrestre: {file}\")\n",
    "        for trace in st:\n",
    "            print(trace)\n",
    "            trace.plot()\n",
    "            # Realiza la transformada de Fourier\n",
    "            spectrum_GAW = np.fft.fft(trace.data)\n",
    "        \n",
    "            # Calcula las frecuencias correspondientes\n",
    "            freq_GAW = np.fft.fftfreq(len(trace.data), d=1/trace.stats.sampling_rate)\n",
    "        \n",
    "            # Grafica el espectro\n",
    "            plt.figure()\n",
    "            plt.plot(np.abs(freq_GAW), np.abs(spectrum_GAW))\n",
    "            plt.xlabel('Frecuencia (Hz)')\n",
    "            plt.ylabel('Amplitud')\n",
    "            plt.title('Espectro de onda acústica captada por el sismómetro ' + trace.stats.station + ' - ' + trace.stats.channel,fontsize=12)\n",
    "            plt.grid(True)\n",
    "            # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "            plt.xticks(fontsize=15)\n",
    "            plt.yticks(fontsize=15)\n",
    "            plt.show()\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802729b-2949-46ae-bc63-59a7a642b37e",
   "metadata": {},
   "source": [
    "# Se crea un arreglo con los espectros de las explociones del catalogo del Insivumeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0bd031-17fb-4e98-880a-25cc4b884b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from obspy import read\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directorio donde se encuentran los archivos MSEED\n",
    "directory = \"slices\"\n",
    "\n",
    "# Verifica si el directorio existe\n",
    "if not os.path.exists(directory):\n",
    "    print(f\"El directorio '{directory}' no existe.\")\n",
    "    exit()\n",
    "\n",
    "# Obtén la lista de archivos MSEED en el directorio\n",
    "mseed_files = [file for file in os.listdir(directory) if file.endswith(\".mseed\")]\n",
    "\n",
    "# Listas para almacenar los espectros y frecuencias\n",
    "spectra_seismic = []\n",
    "freqs_seismic = []\n",
    "signal_seismic = []\n",
    "spectra_AAW = []\n",
    "freqs_AAW = []\n",
    "signal_AAW = []\n",
    "\n",
    "spectra_GAW = []\n",
    "freqs_GAW = []\n",
    "signal_GAW = []\n",
    "\n",
    "# Itera sobre cada archivo MSEED\n",
    "for file in mseed_files:\n",
    "    # Lee el archivo MSEED\n",
    "    st = read(os.path.join(directory, file))\n",
    "    \n",
    "    # Itera sobre cada traza en el archivo MSEED\n",
    "    for trace in st:\n",
    "        # Realiza la transformada de Fourier\n",
    "        spectrum = np.fft.fft(trace.data)\n",
    "        \n",
    "        # Calcula las frecuencias correspondientes\n",
    "        freq = np.fft.fftfreq(len(trace.data), d=1/trace.stats.sampling_rate)\n",
    "        \n",
    "        # Verifica el tipo de onda y agrega el espectro y las frecuencias correspondientes a las listas adecuadas\n",
    "        if \"seismic\" in file:\n",
    "            signal_seismic.append(trace.data)\n",
    "            spectra_seismic.append(np.abs(spectrum))\n",
    "            freqs_seismic.append(freq)\n",
    "        elif \"AAW\" in file:\n",
    "            signal_AAW.append(trace.data)\n",
    "            spectra_AAW.append(np.abs(spectrum))\n",
    "            freqs_AAW.append(freq)\n",
    "        else:\n",
    "            signal_GAW.append(trace.data)\n",
    "            spectra_GAW.append(np.abs(spectrum))\n",
    "            freqs_GAW.append(freq)\n",
    "# Ahora se tienen los espectros y frecuencias de cada tipo de onda en listas separadas\n",
    "# Ahora se puede comparar estas listas como desees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e29b88d-f0ff-48c8-a05b-c36b84d98023",
   "metadata": {},
   "source": [
    "#  Función que realiza las correlaciones cruzadas del dominio de la frecuencia entre un candidato a explosión volcánica y las explosiones confirmadas del catálogo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea5cbe-79f1-4112-9637-65079e4e8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_correlaciones_cruzadas_dominio_frecuencia(signal_test, spectrum_test, freq_test, signal_list, spectrum_list, freq_list):\n",
    "    kurt_freq = []\n",
    "    kurt_spectrum = []\n",
    "    kurt_signal = []\n",
    "\n",
    "    corr_sg = []\n",
    "    corr_f = []\n",
    "    corr_s = []\n",
    "\n",
    "    dens_sg = []\n",
    "    dens_f = []\n",
    "    dens_s = []\n",
    "    \n",
    "    for signal_d,spectrum, freq in zip(signal_list,spectrum_list, freq_list):\n",
    "        norm_spectrum_test = np.abs(spectrum_test) / np.max(np.abs(spectrum_test))\n",
    "        norm_spectrum = np.abs(spectrum) / np.max(np.abs(spectrum))\n",
    "        \n",
    "        norm_freq_test = freq_test / np.max(freq_test)\n",
    "        norm_freq = freq / np.max(freq)\n",
    "        \n",
    "        # Calcula la correlación cruzada entre los espectros y las frecuencias normalizadas\n",
    "        correlation_signal = signal.correlate(signal_test, signal_d, mode='same', method='fft')\n",
    "        correlation_spectrum = signal.correlate(norm_spectrum_test, norm_spectrum, mode='same', method='fft')#np.correlate(norm_spectrum_test, norm_spectrum)\n",
    "        correlation_freq = signal.correlate(norm_freq_test, norm_freq, mode='same', method='fft')#np.correlate(norm_freq_test, norm_freq)\n",
    "\n",
    "        correlation_signal /= np.max(np.abs(correlation_signal))\n",
    "        correlation_spectrum /= np.max(np.abs(correlation_spectrum))\n",
    "        correlation_freq /= np.max(np.abs(correlation_freq))\n",
    "        \n",
    "        corr_sg.append( correlation_signal)\n",
    "        corr_f.append( correlation_freq)\n",
    "        corr_s.append( correlation_spectrum)\n",
    "        \n",
    "        signal_densidad = gaussian_kde(correlation_signal)\n",
    "        freq_densidad     =gaussian_kde(correlation_freq)\n",
    "        spectrum_densidad =gaussian_kde(correlation_spectrum)\n",
    "        \n",
    "        dens_sg.append(signal_densidad)\n",
    "        dens_f.append(freq_densidad)\n",
    "        dens_s.append(spectrum_densidad)\n",
    "        \n",
    "        k_sg = kurtosis(correlation_signal)\n",
    "        k_f =  kurtosis(correlation_freq)\n",
    "        k_s = kurtosis(correlation_spectrum)\n",
    "\n",
    "        kurt_signal.append(k_sg)\n",
    "        kurt_freq.append   (k_f)\n",
    "        kurt_spectrum.append (k_s)\n",
    "        \n",
    "    print(Fore.BLUE + \"        ===============Correlación cruzada normalizada entre spectrum test y list===============\" + Style.RESET_ALL)\n",
    "    plt.plot(corr_s[np.argmax(kurt_spectrum)], label='Correlación cruzada spectrum (test-list)', color='orange')\n",
    "    plt.xlabel('Desplazamiento', fontsize=15)\n",
    "    plt.ylabel('Valor de correlación', fontsize=15)\n",
    "\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    print(Fore.BLUE + \"        ===============Correlación cruzada normalizada entre signal test y list===============\" + Style.RESET_ALL)\n",
    "    plt.plot(corr_sg[np.argmax(kurt_signal)], label='Correlación cruzada signal (test-list)', color='orange')\n",
    "    plt.xlabel('Desplazamiento', fontsize=15)\n",
    "    plt.ylabel('Valor de correlación', fontsize=15)\n",
    "\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    print(Fore.BLUE + \"        ===============Densidad de la correlación cruzada spectrum test y list===============\" + Style.RESET_ALL)\n",
    "    x1 = np.linspace(min(correlation_spectrum), max(correlation_spectrum), 100)\n",
    "    plt.plot(x1, dens_s[np.argmax(kurt_spectrum)](x1), label='Densidad spectrum (test-list)', color='green')\n",
    "    plt.xlabel('Valor de correlación', fontsize=15)\n",
    "    plt.ylabel('Densidad', fontsize=15)\n",
    "\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    print(Fore.BLUE + \"        ===============Densidad de la correlación cruzada signal test y list===============\" + Style.RESET_ALL)\n",
    "    x1 = np.linspace(min(correlation_signal), max(correlation_signal), 100)\n",
    "    plt.plot(x1, dens_sg[np.argmax(kurt_signal)](x1), label='Densidad signal (test-list)', color='green')\n",
    "    plt.xlabel('Valor de correlación', fontsize=15)\n",
    "    plt.ylabel('Densidad', fontsize=15)\n",
    "\n",
    "    # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "    # Imprime los resultados\n",
    "    print(\"kurtosis de la correlación cruzada de señales:\", kurt_signal[np.argmax(kurt_signal)])\n",
    "    print(\"kurtosis de la correlación cruzada de espectros:\", kurt_spectrum[np.argmax(kurt_spectrum)])\n",
    "    print(\"kurtosis de la correlación cruzada de frecuencias:\", kurt_freq[np.argmax(kurt_freq)])\n",
    "    print(\"Densidad de la correlacion cruzada spectrum (0): \",dens_s[np.argmax(kurt_spectrum)](0))\n",
    "    print(\"Densidad de la correlacion cruzada spectrum (1): \",dens_s[np.argmax(kurt_spectrum)](1))\n",
    "    print(\"Densidad de la correlacion cruzada señal (-0.5): \",dens_sg[np.argmax(kurt_signal)](-0.5))\n",
    "    print(\"Densidad de la correlacion cruzada señal (0.5): \",dens_sg[np.argmax(kurt_signal)](0.5))\n",
    "        \n",
    "    print(\"-\" * 40)\n",
    "    return kurt_spectrum[np.argmax(kurt_spectrum)], kurt_signal[np.argmax(kurt_signal)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab9784-4022-40d3-83a9-123af2def3fc",
   "metadata": {},
   "source": [
    "# Se realizan las correlaciones con los recortes de prueba del catalogo del insivumeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b215e816-6d31-4360-824e-b495f5294e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Inicializar colorama\n",
    "init()\n",
    "st__HDF = read(\"GI.FG12.02.BDF.D.2022.260.mseed\")\n",
    "st__EHZ = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "st__SMC = read(\"GI.FG12.00.BHZ.D.2022.260.mseed\")\n",
    "\n",
    "fmin_HDF=0.5\n",
    "fmax_HDF=20\n",
    "fmin_EHZ = 5#0.5 #5 #.5\n",
    "fmax_EHZ = 15#5   #15 #7\n",
    "fmin_seismic = 0.2\n",
    "fmax_seismic = 7\n",
    "\n",
    "st_HDF   = st__HDF.filter('bandpass', freqmin= fmin_HDF, freqmax=fmax_HDF, corners=2, zerophase=True)\n",
    "st_EHZ = st__EHZ.filter('bandpass', freqmin= fmin_EHZ, freqmax=fmax_EHZ, corners=2, zerophase=True)\n",
    "st_smc = st__SMC.filter('highpass', freq= fmin_seismic,                       corners=8, zerophase=True)\n",
    "tr_HDF = st_HDF[0]\n",
    "tr_EHZ = st_EHZ[0]\n",
    "\n",
    "# Define una lista de colores para las trazas\n",
    "colors = [\"red\", \"blue\"]\n",
    "\n",
    "caso_1 =0\n",
    "caso_2 =0\n",
    "caso_3 =0\n",
    "caso_4 =0\n",
    "confirmed = 0\n",
    "indice_confirmacion = []\n",
    "\n",
    "df_intervalos_2 = pd.read_excel(\"df_intervalos_2.xlsx\")\n",
    "for i, eventos_row in df_intervalos_2.iterrows():\n",
    "    event__ini = UTC(eventos_row.event_ini)\n",
    "    event__fin = UTC(eventos_row.event_fin)\n",
    "    seismic__ini = UTC(eventos_row.seismic_ini)\n",
    "    seismic__fin = UTC(eventos_row.seismic_fin)\n",
    "\n",
    "    if  eventos_row.explosion_volcanica >0 and seismic__ini <= event__ini and  seismic__fin >= event__fin and eventos_row.explosion_volcanica >0:\n",
    "        print(\"\")\n",
    "        print(\"---------------------------------------------------- ----------------------------------------------------\")\n",
    "        print(\"aplico s[ e[ e] s]\")\n",
    "        print (eventos_row.explosion_volcanica, \"seismic_ini\", seismic__ini, \"event_ini\", event__ini,\"event_fin\", event__fin, \"seismic fin\", seismic__fin)\n",
    "\n",
    "        AAW_test = st_HDF.slice(seismic__ini, seismic__fin)\n",
    "        GAW_test = st_EHZ.slice(seismic__ini, seismic__fin)\n",
    "        seismic_test = st_smc.slice(seismic__ini, seismic__fin)\n",
    "        \n",
    "        AAW_test.plot(color = \"red\")\n",
    "        GAW_test.plot(color = \"blue\")\n",
    "        seismic_test.plot(color=\"green\")\n",
    "\n",
    "         # Realiza la transformada de Fourier\n",
    "        spectrum_seismic_test = np.fft.fft(seismic_test[0].data)\n",
    "        spectrum_AAW_test = np.fft.fft(AAW_test[0].data)\n",
    "        spectrum_GAW_test = np.fft.fft(GAW_test[0].data)\n",
    "\n",
    "        # Calcula las frecuencias correspondientes\n",
    "        freq_seismic_test = np.fft.fftfreq(len(seismic_test[0].data), d=1/seismic_test[0].stats.sampling_rate)\n",
    "        freq_AAW_test = np.fft.fftfreq(len(AAW_test[0].data), d=1/AAW_test[0].stats.sampling_rate)\n",
    "        freq_GAW_test = np.fft.fftfreq(len(GAW_test[0].data), d=1/GAW_test[0].stats.sampling_rate)\n",
    "        \n",
    "        caso_1+=1\n",
    "    \n",
    "    elif eventos_row.explosion_volcanica >0 and seismic__ini <= event__ini and  seismic__fin <= event__fin and seismic__fin> event__ini  and eventos_row.explosion_volcanica >0:\n",
    "        print(\"\")\n",
    "        print(\"---------------------------------------------------- ----------------------------------------------------\")\n",
    "        print(\"aplico s[ e[ s] e]\")\n",
    "        print (eventos_row.explosion_volcanica, \"seismic_ini\", seismic__ini, \"event_ini\", event__ini,\"seismic_fin\", event__fin, \"event fin\", seismic__fin)\n",
    "\n",
    "        AAW_test = st_HDF.slice(seismic__ini, event__fin)\n",
    "        GAW_test = st_EHZ.slice(seismic__ini, event__fin)\n",
    "        seismic_test = st_smc.slice(seismic__ini, event__fin)\n",
    "        \n",
    "        AAW_test.plot(color = \"red\")\n",
    "        GAW_test.plot(color = \"blue\")\n",
    "        seismic_test.plot(color=\"green\")\n",
    "\n",
    "        # Realiza la transformada de Fourier\n",
    "        spectrum_seismic_test = np.fft.fft(seismic_test[0].data)\n",
    "        spectrum_AAW_test = np.fft.fft(AAW_test[0].data)\n",
    "        spectrum_GAW_test = np.fft.fft(GAW_test[0].data)\n",
    "\n",
    "        # Calcula las frecuencias correspondientes\n",
    "        freq_seismic_test = np.fft.fftfreq(len(seismic_test[0].data), d=1/seismic_test[0].stats.sampling_rate)\n",
    "        freq_AAW_test = np.fft.fftfreq(len(AAW_test[0].data), d=1/AAW_test[0].stats.sampling_rate)\n",
    "        freq_GAW_test = np.fft.fftfreq(len(GAW_test[0].data), d=1/GAW_test[0].stats.sampling_rate)\n",
    "        \n",
    "        caso_2+=1\n",
    "\n",
    "    elif eventos_row.explosion_volcanica >0 and seismic__ini >= event__ini and  seismic__fin >= event__fin and event__fin> seismic__ini and eventos_row.explosion_volcanica >0:\n",
    "        print(\"\")\n",
    "        print(\"---------------------------------------------------- ----------------------------------------------------\")\n",
    "        print(\"aplico e[ s[ e] s]\")\n",
    "        print (eventos_row.explosion_volcanica, \"event_ini\", event__ini, \"event_ini\", seismic__ini,\"event_fin\", event__fin, \"seismic fin\", seismic__fin)\n",
    "        \n",
    "        AAW_test = st_HDF.slice(event__ini, seismic__fin)\n",
    "        GAW_test = st_EHZ.slice(event__ini, seismic__fin)\n",
    "        seismic_test = st_smc.slice(event__ini, seismic__fin)\n",
    "        \n",
    "        AAW_test.plot(color = \"red\")\n",
    "        GAW_test.plot(color = \"blue\")\n",
    "        seismic_test.plot(color=\"green\")\n",
    " \n",
    "        # Realiza la transformada de Fourier\n",
    "        spectrum_seismic_test = np.fft.fft(seismic_test[0].data)\n",
    "        spectrum_AAW_test = np.fft.fft(AAW_test[0].data)\n",
    "        spectrum_GAW_test = np.fft.fft(GAW_test[0].data)\n",
    "\n",
    "        # Calcula las frecuencias correspondientes\n",
    "        freq_seismic_test = np.fft.fftfreq(len(seismic_test[0].data), d=1/seismic_test[0].stats.sampling_rate)\n",
    "        freq_AAW_test = np.fft.fftfreq(len(AAW_test[0].data), d=1/AAW_test[0].stats.sampling_rate)\n",
    "        freq_GAW_test = np.fft.fftfreq(len(GAW_test[0].data), d=1/GAW_test[0].stats.sampling_rate)\n",
    "        \n",
    "        caso_3 +=1\n",
    " \n",
    "    elif  eventos_row.explosion_volcanica >0:\n",
    "        print(\"\")\n",
    "        print(\"---------------------------------------------------- ----------------------------------------------------\")\n",
    "        print(\"evento\", i, \"aplico { e[ e] s[ s] } o { s[ s] e[e] }\")\n",
    "        print (eventos_row.explosion_volcanica, \"seismic_ini\", seismic__ini, \"seismic fin\", seismic__fin, \"event_ini\", event__ini,\"event_fin\", event__fin)\n",
    "        min_ini = min(event__ini, seismic__ini)\n",
    "        max_fin = max(event__fin, seismic__fin)\n",
    "\n",
    "        AAW_test = st_HDF.slice(min_ini, max_fin)\n",
    "        GAW_test = st_EHZ.slice(min_ini, max_fin)\n",
    "        seismic_test = st_smc.slice(min_ini, max_fin)\n",
    "        \n",
    "        AAW_test.plot(color = \"red\")\n",
    "        GAW_test.plot(color = \"blue\")\n",
    "        seismic_test.plot(color=\"green\")\n",
    "        \n",
    "        # Realiza la transformada de Fourier\n",
    "        spectrum_seismic_test = np.fft.fft(seismic_test[0].data)\n",
    "        spectrum_AAW_test = np.fft.fft(AAW_test[0].data)\n",
    "        spectrum_GAW_test = np.fft.fft(GAW_test[0].data)\n",
    "\n",
    "        # Calcula las frecuencias correspondientes\n",
    "        freq_seismic_test = np.fft.fftfreq(len(seismic_test[0].data), d=1/seismic_test[0].stats.sampling_rate)\n",
    "        freq_AAW_test = np.fft.fftfreq(len(AAW_test[0].data), d=1/AAW_test[0].stats.sampling_rate)\n",
    "        freq_GAW_test = np.fft.fftfreq(len(GAW_test[0].data), d=1/GAW_test[0].stats.sampling_rate)\n",
    "        \n",
    "        caso_4 +=1\n",
    "\n",
    "\n",
    "    # Llama a la función para cada tipo de onda\n",
    "    if  eventos_row.explosion_volcanica >0: \n",
    "        print(\"Comparación con seismic:\")\n",
    "        k_spc_seismic, k_sgn_seismic = calcular_correlaciones_cruzadas_dominio_frecuencia(seismic_test[0].data,spectrum_seismic_test, freq_seismic_test, signal_seismic, spectra_seismic, freqs_seismic)\n",
    "\n",
    "        print(\"Comparación con AAW:\")\n",
    "        k_spc_AAW, k_sgn_AAW = calcular_correlaciones_cruzadas_dominio_frecuencia(AAW_test[0].data,spectrum_AAW_test, freq_AAW_test, signal_AAW,spectra_AAW, freqs_AAW)\n",
    "\n",
    "        print(\"Comparación con GAW:\")\n",
    "        k_spc_GAW, k_sgn_GAW = calcular_correlaciones_cruzadas_dominio_frecuencia(GAW_test[0].data,spectrum_GAW_test, freq_GAW_test, signal_GAW,spectra_GAW, freqs_GAW)\n",
    "        print('kurt espectro',k_spc_seismic, k_spc_AAW, k_spc_GAW)\n",
    "        print('kurt_señal', k_sgn_seismic, k_sgn_AAW, k_sgn_GAW)\n",
    "        if (k_spc_seismic >= 1.6 or k_spc_AAW >= 1.5 or k_spc_GAW > 1.5) and (k_sgn_seismic >= 5 or k_sgn_AAW >= 5 or k_sgn_GAW > 5):\n",
    "            print(Fore.RED + \"===============EXPLOSION VOLCÁNICA CONFIMADA===============\" + Style.RESET_ALL)\n",
    "            \n",
    "            confirmed +=1\n",
    "            indice_confirmacion.append(eventos_row.explosion_volcanica)\n",
    "        # Grafica el espectro\n",
    "            print(Fore.BLUE + \"        ===============Espectro de onda sismica===============\" + Style.RESET_ALL)\n",
    "            plt.figure()\n",
    "            plt.plot(np.abs(freq_seismic_test), np.abs(spectrum_seismic_test))\n",
    "            plt.xlabel('Frecuencia (Hz)', fontsize=15)\n",
    "            plt.ylabel('Amplitud', fontsize=15)\n",
    "#            plt.title('Espectro de onda sismica ', fontsize=25 )\n",
    "            plt.grid(True)\n",
    "            # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "            plt.xticks(fontsize=14)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.show()\n",
    "        # Grafica el espectro\n",
    "            print(Fore.BLUE + \"        ===============Espectro de onda acustica atmosférica===============\" + Style.RESET_ALL)\n",
    "            plt.figure()\n",
    "            plt.plot(np.abs(freq_AAW_test), np.abs(spectrum_AAW_test))\n",
    "            plt.xlabel('Frecuencia (Hz)', fontsize=15)\n",
    "            plt.ylabel('Amplitud', fontsize=15)\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "            plt.xticks(fontsize=14)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.show()\n",
    "\n",
    "        # Grafica el espectro\n",
    "            print(Fore.BLUE + \"        ===============Espectro de onda acústica captada por el sismómetro===============\" + Style.RESET_ALL)\n",
    "            plt.figure()\n",
    "            plt.plot(np.abs(freq_GAW_test), np.abs(spectrum_GAW_test))\n",
    "            plt.xlabel('Frecuencia (Hz)', fontsize=15)\n",
    "            plt.ylabel('Amplitud', fontsize=15)\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Ajustar el tamaño de la fuente de los ticks de los ejes\n",
    "            plt.xticks(fontsize=14)\n",
    "            plt.yticks(fontsize=14)\n",
    "            plt.show()\n",
    "        else:\n",
    "            indice_confirmacion.append(\"\")\n",
    "    else:\n",
    "        indice_confirmacion.append(\"\")\n",
    "\n",
    "print(caso_1,caso_2,caso_3,caso_4, confirmed)\n",
    "df_intervalos_2['explosion_confirmada'] = indice_confirmacion\n",
    "df_intervalos_2.to_excel(\"df_intervalos_2_confirmed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b1102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
